# 📚 6주 CV & Generative Models 올커버 플랜

> 🎯 목표:  
> - **기초 수학/통계 → 전통적 CV → CNN/Transformer → Diffusion/Flow → RLHF**  
> - 면접에서 어떤 질문이 나와도 "정의 → 수식 → 직관 → 응용"으로 답변 가능  
> - GitHub에 학습 노트와 Mock Q&A를 기록하며 연구 포트폴리오 강화  

---

## 📆 주차별 로드맵

### ✅ Week 1. 수학 + 전통 CV
- **수학/통계 기본기**
  - MLE, MAP, KL Divergence, Cross-Entropy
  - Gradient Descent, Convex Optimization
- **전통 CV**
  - SIFT, HOG, Viola-Jones
  - Convolution 수학적 정의

---

### ✅ Week 2. CNN + Detection/Segmentation
- CNN 아키텍처: LeNet, AlexNet, VGG, ResNet
- Skip connection 수식 & Gradient Vanishing 해결
- IoU 정의 & 계산
- Object Detection: Faster R-CNN, YOLO, SSD
- Segmentation: FCN, U-Net

---

### ✅ Week 3. Transformer 기본 + Vision Transformer
- Attention 수식, Multi-Head Attention
- Encoder vs Decoder 구조, Positional Encoding
- ViT 구조 (Patch Embedding)
- Swin Transformer (Hierarchical Attention)

---

### ✅ Week 4. Autoregressive LM + LoRA/QLoRA
- GPT vs BERT (Autoregressive vs Masked LM)
- Language Modeling Objective
- QLoRA (4-bit quantization + LoRA)
---

### ✅ Week 5. Diffusion 기본 + Stable Diffusion
- DDPM: Forward/Reverse 수식, ELBO 유도
- CFG(Classifier-Free Guidance) 수식 & 직관
- Sampling 방법: DDPM vs DDIM vs Ancestral  //score-based
- Latent Diffusion, VAE 수식, Cross-Attention
---
### ✅ Week 6. Flow Matching + RLHF

- Normalizing Flow (Change of Variables formula)
- Flow Matching Loss, Probability Flow ODE+SDE
- Flow vs Diffusion 비교
- RLHF 단계: SFT → RM → PPO
- RL-guided Diffusion/Flow 개념

### 🔥 활용 방법

매주 2개 테마를 노트로 정리 (수식 + 직관 + 그림 포함)
각 테마마다 예상 면접 질문 10~15개 Mock Q&A 작성
GitHub에 push → "스터디 로그" 형식으로 관리


