# ğŸ“š 6ì£¼ CV & Generative Models ì˜¬ì»¤ë²„ í”Œëœ

> ğŸ¯ ëª©í‘œ:  
> - **ê¸°ì´ˆ ìˆ˜í•™/í†µê³„ â†’ ì „í†µì  CV â†’ CNN/Transformer â†’ Diffusion/Flow â†’ RLHF**  
> - ë©´ì ‘ì—ì„œ ì–´ë–¤ ì§ˆë¬¸ì´ ë‚˜ì™€ë„ "ì •ì˜ â†’ ìˆ˜ì‹ â†’ ì§ê´€ â†’ ì‘ìš©"ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥  
> - GitHubì— í•™ìŠµ ë…¸íŠ¸ì™€ Mock Q&Aë¥¼ ê¸°ë¡í•˜ë©° ì—°êµ¬ í¬íŠ¸í´ë¦¬ì˜¤ ê°•í™”  

---

## ğŸ“† ì£¼ì°¨ë³„ ë¡œë“œë§µ

### âœ… Week 1. ìˆ˜í•™ + ì „í†µ CV
- **ìˆ˜í•™/í†µê³„ ê¸°ë³¸ê¸°**
  - MLE, MAP, KL Divergence, Cross-Entropy
  - Gradient Descent, Convex Optimization
- **ì „í†µ CV**
  - SIFT, HOG, Viola-Jones
  - Convolution ìˆ˜í•™ì  ì •ì˜

---

### âœ… Week 2. CNN + Detection/Segmentation
- CNN ì•„í‚¤í…ì²˜: LeNet, AlexNet, VGG, ResNet
- Skip connection ìˆ˜ì‹ & Gradient Vanishing í•´ê²°
- IoU ì •ì˜ & ê³„ì‚°
- Object Detection: Faster R-CNN, YOLO, SSD
- Segmentation: FCN, U-Net

---

### âœ… Week 3. Transformer ê¸°ë³¸ + Vision Transformer
- Attention ìˆ˜ì‹, Multi-Head Attention
- Encoder vs Decoder êµ¬ì¡°, Positional Encoding
- ViT êµ¬ì¡° (Patch Embedding)
- Swin Transformer (Hierarchical Attention)

---

### âœ… Week 4. Autoregressive LM + LoRA/QLoRA
- GPT vs BERT (Autoregressive vs Masked LM)
- Language Modeling Objective
- QLoRA (4-bit quantization + LoRA)
---

### âœ… Week 5. Diffusion ê¸°ë³¸ + Stable Diffusion
- DDPM: Forward/Reverse ìˆ˜ì‹, ELBO ìœ ë„
- CFG(Classifier-Free Guidance) ìˆ˜ì‹ & ì§ê´€
- Sampling ë°©ë²•: DDPM vs DDIM vs Ancestral  //score-based
- Latent Diffusion, VAE ìˆ˜ì‹, Cross-Attention
---
### âœ… Week 6. Flow Matching + RLHF

- Normalizing Flow (Change of Variables formula)
- Flow Matching Loss, Probability Flow ODE+SDE
- Flow vs Diffusion ë¹„êµ
- RLHF ë‹¨ê³„: SFT â†’ RM â†’ PPO
- RL-guided Diffusion/Flow ê°œë…

### ğŸ”¥ í™œìš© ë°©ë²•

ë§¤ì£¼ 2ê°œ í…Œë§ˆë¥¼ ë…¸íŠ¸ë¡œ ì •ë¦¬ (ìˆ˜ì‹ + ì§ê´€ + ê·¸ë¦¼ í¬í•¨)
ê° í…Œë§ˆë§ˆë‹¤ ì˜ˆìƒ ë©´ì ‘ ì§ˆë¬¸ 10~15ê°œ Mock Q&A ì‘ì„±
GitHubì— push â†’ "ìŠ¤í„°ë”” ë¡œê·¸" í˜•ì‹ìœ¼ë¡œ ê´€ë¦¬


