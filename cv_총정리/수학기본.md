# 수학 기본(확률/통계/추정/최적)

---

## 목차
0. [기호와 관례](#0-기호와-관례)
1. [확률론 기초](#1-확률론-기초)
2. [정보 이론](#2-정보-이론)

---

## 0. 기호와 관례
---
### 0.1 확률변수 (Random Variable)
확률 실험의 결과를 숫자로 나타내는 함수

**표기**: 대문자 $X$, $Y$, $Z$

**종류**:
- **이산확률변수 (Discrete Random Variable)**
  - 가질 수 있는 값이 셀 수 있는 경우
  - 예: 주사위 눈금, 동전 던지기 횟수
  
- **연속확률변수 (Continuous Random Variable)**
  - 가질 수 있는 값이 특정 구간 내 모든 실수값
  - 예: 키, 몸무게, 온도
---
### 0.2 실현값 (Realization)
실제 확률 실험을 한 번 했을 때 관측되는 특정 결과값

**표기**: 소문자 $x$, $y$, $z$

**예시**: 주사위를 던져서 3이 나왔다면 $x = 3$
---
### 0.3 확률 함수 (Probability Function)
확률변수가 어떤 값을 가질 확률을 나타내는 함수

#### (1) 확률질량함수 (Probability Mass Function, PMF)
- **용도**: 이산확률변수
- **표기**: $p_X(x)$ 또는 $P(X = x)$
- **의미**: 확률변수 $X$가 정확히 $x$라는 값을 가질 확률
- **특징**: 
  - $0 \leq p_X(x) \leq 1$
  - $\sum_x p_X(x) = 1$
- **예시**: $P(X = 3) = 0.2$ (X가 3일 확률 20%)

#### (2) 확률밀도함수 (Probability Density Function, PDF)
- **용도**: 연속확률변수
- **표기**: $f_X(x)$ 또는 $p(x)$
- **의미**: 확률변수 $X$가 $x$ 근처에 밀집되어 있는 정도 (그래프의 높이)
- **특징**:
  - $f_X(x) \geq 0$ (1보다 클 수 있음!)
  - $\int_{-\infty}^{\infty} f_X(x) dx = 1$
  - $P(X = x) = 0$ (정확히 특정 값일 확률은 0)
  - $P(a \leq X \leq b) = \int_a^b f_X(x) dx$ (구간 확률은 면적)
---
### 0.4 누적분포함수 (Cumulative Distribution Function, CDF)
- **표기**: $F_X(x)$
- **정의**: $F_X(x) = P(X \leq x)$
- **의미**: 확률변수 $X$가 특정값 $x$이하의 값을 가질 확률 나타내는 함수 (이산/연속 확률 변수 모두에 적용 가능)
- **관계**:
  - 이산: $F_X(x) = \sum_{t \leq x} p_X(t)$
  - 연속: $F_X(x) = \int_{-\infty}^x f_X(t) dt$
  - $f_X(x) = \frac{d}{dx} F_X(x)$ (PDF는 CDF의 미분)
  - 절대 감소하지 않는 단조 증가 함수
---
### 0.5 기대값(Expectation)
- **의미**:  확률변수 $X$가 가질수 있는 값들의 가중평균 (무수히 많은 실험 했을때 X가 취하게 될 값 즉, **분포의 중심**)
- **표기**:
  - **이산**: $\mathbb{E}[X] = \sum_x x \cdot p_X(x)$
  - **연속**: $\mathbb{E}[X] = \int_{-\infty}^{\infty} x \cdot f_X(x) dx$
---
### 0.6 분산(Variance)
- **정의**:  $\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2$
- **의미**: 확률변수 X가 기대값 $\mathbb{E}[X]$로 부터 얼마나 넓게 퍼져있는가.
- 분산의 양의 제곱근이 표준편차($\sigma_x$)이며, 흩어진 정도를 $X$와 같은 단위로 표시한 것
---
### 0.7 공분산(Covariance)
- **표기**: $$\text{Cov}(X, Y) = \mathbb{E}[(X - \mu_X)(Y - \mu_Y)] = \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y]$$
- **의미**: 두 확률 변수 X,Y가 어떻게 변하는지(**선형관계**)를 나타내는 척도.
- 상관관계: 공분산을 표준화하여 $-1 \leq \text{Cov}(X,Y) \leq 1$ 로 만든 측도

---

## 1. 확률론 기초
---
### 1.1 표본공간 (Sample Space)
- **표기**: $\Omega$
- **정의**: 확률실험에서 나올 수 있는 모든 가능한 결과들의 집합
- **사건 (Event)**: 표본공간의 부분집합 $A \subseteq \Omega$
- **예시**:
  - 동전 던지기: $\Omega = \{H, T\}$
  - 주사위: $\Omega = \{1, 2, 3, 4, 5, 6\}$

---
### 1.2 Kolmogorov 공리 (확률측도 $P$)
표본공간의 각 사건에 확률이라는 숫자를 부여하는 함수

**세 가지 공리**:
1. **비음성 (Non-negativity)**: $P(A) \geq 0$ for all $A \subseteq \Omega$
2. **정규성 (Normalization)**: $P(\Omega) = 1$
3. **가산가법성 (Countable Additivity)**: 서로 배반인 사건들 $A_1, A_2, \ldots$ (즉, $A_i \cap A_j = \emptyset$ for $i \neq j$)에 대해
   $$P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)$$

---
### 1.3 조건부 확률 (Conditional Probability)
사건 $B$가 일어났다는 조건 하에서 사건 $A$가 일어날 확률

**이산 사건**:
$$P(A|B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) > 0$$

**연속확률변수**:
$$p(x|y) = \frac{p(x, y)}{p(y)}, \quad p(y) > 0$$

**성질**:
- $P(A \cap B) = P(A|B)P(B) = P(B|A)P(A)$
- 독립: $P(A|B) = P(A)$ ⟺ $P(A \cap B) = P(A)P(B)$

---
### 1.4 전확률 공식 (Law of Total Probability)
표본공간을 분할하는 사건들 $B_1, B_2, \ldots, B_n$ (즉, $\bigcup_i B_i = \Omega$이고 서로 배반)에 대해:

**이산**:
$$P(A) = \sum_{i=1}^{n} P(A|B_i)P(B_i)$$

**연속**:
$$p(x) = \int p(x|y)p(y) dy$$

**의미**: 모든 경우를 고려하여 전체 확률 계산

---
### 1.5 베이즈 정리 (Bayes' Theorem)
관찰 후 확률을 업데이트하는 공식

**기본 형태**:
$$P(B|A) = \frac{P(A|B)P(B)}{P(A)}$$

**전확률 공식 결합**:
$$P(B_i|A) = \frac{P(A|B_i)P(B_i)}{\sum_{j} P(A|B_j)P(B_j)}$$

**연속확률변수**:
$$p(\theta|x) = \frac{p(x|\theta)p(\theta)}{p(x)} = \frac{p(x|\theta)p(\theta)}{\int p(x|\theta)p(\theta) d\theta}$$

**용어**:
- $P(\theta)$ 또는 $p(\theta)$: **사전확률 (prior)** - 관찰 전 믿음
- $P(x|\theta)$ 또는 $p(x|\theta)$: **가능도 (likelihood)** - 데이터가 관찰될 확률
- $P(\theta|x)$ 또는 $p(\theta|x)$: **사후확률 (posterior)** - 관찰 후 업데이트된 믿음
- $P(x)$ 또는 $p(x)$: **증거/주변확률 (evidence/marginal)** - 정규화 상수

**해석**: 
$$\text{posterior} = \frac{\text{likelihood} \times \text{prior}}{\text{evidence}}$$

---
## 2. 확률분포 (Probability Distributions)

---

### 2.1 이산확률분포 (Discrete Probability Distributions)

#### 2.1.1 베르누이 분포 (Bernoulli Distribution)
성공/실패 같은 이진 결과를 모델링

**표기**: $X \sim \text{Bernoulli}(p)$

**확률질량함수**:
$$P(X = x) = p^x(1-p)^{1-x}, \quad x \in \{0, 1\}$$

**기댓값**: $\mathbb{E}[X] = p$

**분산**: $\text{Var}(X) = p(1-p)$

**예시**: 동전 던지기, 시험 합격/불합격

---

#### 2.1.2 이항분포 (Binomial Distribution)
$n$번의 독립적인 베르누이 시행에서 성공 횟수

**표기**: $X \sim \text{Binomial}(n, p)$

**확률질량함수**:
$$P(X = k) = \binom{n}{k}p^k(1-p)^{n-k}, \quad k = 0, 1, \ldots, n$$

**기댓값**: $\mathbb{E}[X] = np$

**분산**: $\text{Var}(X) = np(1-p)$

**예시**: $n$번 동전 던져서 앞면 나온 횟수

---

#### 2.1.3 기하분포 (Geometric Distribution)
첫 번째 성공까지의 시행 횟수

**표기**: $X \sim \text{Geometric}(p)$

**확률질량함수**:
$$P(X = k) = (1-p)^{k-1}p, \quad k = 1, 2, 3, \ldots$$

**기댓값**: $\mathbb{E}[X] = \frac{1}{p}$

**분산**: $\text{Var}(X) = \frac{1-p}{p^2}$

**예시**: 주사위를 던져서 6이 처음 나올 때까지의 횟수

---

#### 2.1.4 포아송 분포 (Poisson Distribution)
일정 시간/공간에서 발생하는 사건의 횟수

**표기**: $X \sim \text{Poisson}(\lambda)$

**확률질량함수**:
$$P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}, \quad k = 0, 1, 2, \ldots$$

**기댓값**: $\mathbb{E}[X] = \lambda$

**분산**: $\text{Var}(X) = \lambda$

**예시**: 1시간 동안 들어오는 전화 건수, 웹사이트 방문자 수

---

### 2.2 연속확률분포 (Continuous Probability Distributions)

#### 2.2.1 균등분포 (Uniform Distribution)
구간 내 모든 값이 동일한 확률밀도

**표기**: $X \sim \text{Uniform}(a, b)$

**확률밀도함수**:
$$f(x) = \begin{cases} \frac{1}{b-a} & a \leq x \leq b \\ 0 & \text{otherwise} \end{cases}$$

**기댓값**: $\mathbb{E}[X] = \frac{a+b}{2}$

**분산**: $\text{Var}(X) = \frac{(b-a)^2}{12}$

**예시**: 난수 생성, 버스 대기 시간

---

#### 2.2.2 정규분포 (Normal/Gaussian Distribution)
자연 현상에서 가장 흔한 종 모양 분포

**표기**: $X \sim \mathcal{N}(\mu, \sigma^2)$

**확률밀도함수**:
$$f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$$

**기댓값**: $\mathbb{E}[X] = \mu$

**분산**: $\text{Var}(X) = \sigma^2$

**표준정규분포**: $Z \sim \mathcal{N}(0, 1)$일 때 $Z = \frac{X - \mu}{\sigma}$

**예시**: 키, 몸무게, 측정 오차

**중요 성질**:
- 68-95-99.7 규칙 (경험 규칙)
- 중심극한정리: 표본평균은 정규분포에 수렴

---

#### 2.2.3 지수분포 (Exponential Distribution)
사건 발생까지의 대기 시간

**표기**: $X \sim \text{Exp}(\lambda)$

**확률밀도함수**:
$$f(x) = \lambda e^{-\lambda x}, \quad x \geq 0$$

**기댓값**: $\mathbb{E}[X] = \frac{1}{\lambda}$

**분산**: $\text{Var}(X) = \frac{1}{\lambda^2}$

**예시**: 다음 고객 도착까지 시간, 기계 고장까지 시간

**특징**: 무기억성 (memoryless property)

---

#### 2.2.4 감마분포 (Gamma Distribution)
$k$번째 사건 발생까지의 대기 시간 (지수분포의 일반화)

**표기**: $X \sim \text{Gamma}(\alpha, \beta)$

**확률밀도함수**:
$$f(x) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x}, \quad x > 0$$

여기서 $\Gamma(\alpha) = \int_0^\infty t^{\alpha-1}e^{-t}dt$ (감마 함수)

**기댓값**: $\mathbb{E}[X] = \frac{\alpha}{\beta}$

**분산**: $\text{Var}(X) = \frac{\alpha}{\beta^2}$

**특수 케이스**: $\alpha = 1$일 때 지수분포

---

#### 2.2.5 베타분포 (Beta Distribution)
$[0, 1]$ 구간의 확률이나 비율을 모델링

**표기**: $X \sim \text{Beta}(\alpha, \beta)$

**확률밀도함수**:
$$f(x) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha-1}(1-x)^{\beta-1}, \quad 0 \leq x \leq 1$$

**기댓값**: $\mathbb{E}[X] = \frac{\alpha}{\alpha + \beta}$

**분산**: $\text{Var}(X) = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$

**용도**: 베르누이/이항분포의 공액사전분포

**예시**: 성공 확률 추정, 비율 데이터

---

### 2.3 표본분포 (Sampling Distributions)

#### 2.3.1 카이제곱 분포 (Chi-squared Distribution)
독립적인 표준정규분포 제곱의 합

**표기**: $X \sim \chi^2(k)$ (자유도 $k$)

**정의**: $Z_1, \ldots, Z_k \sim \mathcal{N}(0,1)$ 독립이면
$$X = \sum_{i=1}^k Z_i^2 \sim \chi^2(k)$$

**확률밀도함수**:
$$f(x) = \frac{1}{2^{k/2}\Gamma(k/2)} x^{k/2-1} e^{-x/2}, \quad x > 0$$

**기댓값**: $\mathbb{E}[X] = k$

**분산**: $\text{Var}(X) = 2k$

**용도**: 
- 분산 추정
- 적합도 검정 (goodness-of-fit test)
- 독립성 검정

**특징**: 감마분포의 특수 케이스 $\text{Gamma}(k/2, 1/2)$

---

#### 2.3.2 t-분포 (Student's t-Distribution)
표본평균의 분포 (모분산을 모를 때)

**표기**: $T \sim t(k)$ (자유도 $k$)

**정의**: $Z \sim \mathcal{N}(0,1)$, $V \sim \chi^2(k)$ 독립이면
$$T = \frac{Z}{\sqrt{V/k}} \sim t(k)$$

**확률밀도함수**:
$$f(x) = \frac{\Gamma((k+1)/2)}{\sqrt{k\pi}\Gamma(k/2)}\left(1 + \frac{x^2}{k}\right)^{-(k+1)/2}$$

**기댓값**: $\mathbb{E}[T] = 0$ (단, $k > 1$)

**분산**: $\text{Var}(T) = \frac{k}{k-2}$ (단, $k > 2$)

**용도**:
- 모평균 검정/신뢰구간 (표본 크기 작을 때)
- 회귀계수 유의성 검정

**특징**: 
- 정규분포보다 두꺼운 꼬리 (heavy tail)
- $k \to \infty$일 때 표준정규분포로 수렴

---

#### 2.3.3 F-분포 (F-Distribution)
두 카이제곱 분포 비율

**표기**: $F \sim F(d_1, d_2)$ (자유도 $d_1, d_2$)

**정의**: $V_1 \sim \chi^2(d_1)$, $V_2 \sim \chi^2(d_2)$ 독립이면
$$F = \frac{V_1/d_1}{V_2/d_2} \sim F(d_1, d_2)$$

**확률밀도함수**:
$$f(x) = \frac{\Gamma((d_1+d_2)/2)}{\Gamma(d_1/2)\Gamma(d_2/2)} \left(\frac{d_1}{d_2}\right)^{d_1/2} \frac{x^{d_1/2-1}}{(1 + d_1x/d_2)^{(d_1+d_2)/2}}, \quad x > 0$$

**기댓값**: $\mathbb{E}[F] = \frac{d_2}{d_2-2}$ (단, $d_2 > 2$)

**분산**: $\text{Var}(F) = \frac{2d_2^2(d_1+d_2-2)}{d_1(d_2-2)^2(d_2-4)}$ (단, $d_2 > 4$)

**용도**:
- 분산비 검정
- ANOVA (분산분석)
- 회귀모형의 전체 유의성 검정

---

### 2.4 다변량 정규분포 (Multivariate Normal Distribution)

**표기**: $\mathbf{X} \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})$

**확률밀도함수**:
$$f(\mathbf{x}) = \frac{1}{(2\pi)^{d/2}|\boldsymbol{\Sigma}|^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^T\boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right)$$

여기서:
- $\mathbf{x}, \boldsymbol{\mu} \in \mathbb{R}^d$ ($d$차원 벡터)
- $\boldsymbol{\Sigma}$: $d \times d$ 공분산 행렬 (양정부호)

**기댓값**: $\mathbb{E}[\mathbf{X}] = \boldsymbol{\mu}$

**공분산**: $\text{Cov}(\mathbf{X}) = \boldsymbol{\Sigma}$

**용도**: 고차원 데이터 모델링, 가우시안 프로세스

---

### 2.5 분포 간 관계
### 2.5 분포 간 관계

**표준정규분포에서 파생**:

1. **카이제곱 분포**: 
   - $Z_1, \ldots, Z_k \sim \mathcal{N}(0,1)$ 독립
   - $\sum_{i=1}^k Z_i^2 \sim \chi^2(k)$

2. **t-분포**: 
   - $Z \sim \mathcal{N}(0,1)$, $V \sim \chi^2(k)$ 독립
   - $T = \frac{Z}{\sqrt{V/k}} \sim t(k)$

3. **F-분포**: 
   - $V_1 \sim \chi^2(d_1)$, $V_2 \sim \chi^2(d_2)$ 독립
   - $F = \frac{V_1/d_1}{V_2/d_2} \sim F(d_1, d_2)$

**관계도**:

    표준정규분포 N(0,1)
          |
          | (제곱의 합)
          v
      카이제곱 분포
          |                    |
          | (비율)              | (비율)
          v                    v
        t-분포              F-분포

**기타 관계**:
- 이항분포 → 정규분포 (n이 클 때)
- 포아송분포 → 정규분포 (λ가 클 때)  
- t-분포 → 표준정규분포 (자유도가 클 때)
- 지수분포 = 감마분포 (α=1)
- 카이제곱분포 = 감마분포 (α=k/2, β=1/2)

---

## 3. 정보이론 (Information Theory)

---

### 3.1 엔트로피 (Entropy)
**불확실성 또는 정보량의 측정**

#### 이산 엔트로피
$$H(X) = -\sum_x P(x) \log P(x)$$

#### 미분 엔트로피 (연속)
$$h(X) = -\int p(x) \log p(x) \, dx$$

**의미**:
- 확률분포의 불확실성/무질서도
- 최적 인코딩에 필요한 평균 비트 수
- 균등분포일 때 최대값

**특징**:
- 이산: $H(X) \geq 0$ (항상 비음수)
- 연속: $h(X)$ 음수 가능 (밀도가 1보다 큰 경우)

**예시**:
- 동전 (공정): $H = 1$ bit
- 동전 (90% 앞면): $H \approx 0.47$ bit (더 확실하므로 낮음)

---

### 3.2 크로스 엔트로피 (Cross Entropy)
**분포 $Q$를 사용해 분포 $P$를 인코딩하는 비용**

#### 정의
$$H(P, Q) = -\sum_x P(x) \log Q(x)$$

**연속**:
$$H(p, q) = -\int p(x) \log q(x) \, dx$$

**의미**:
- $P$: 실제 분포
- $Q$: 모델 분포
- 모델 $Q$로 실제 데이터 $P$를 설명하는 비효율성

**성질**:
- $H(P, Q) \geq H(P)$ (등호는 $P = Q$일 때)
- 비대칭: $H(P, Q) \neq H(Q, P)$

---

### 3.3 KL 다이버전스 (Kullback-Leibler Divergence)
**두 확률분포 간의 차이 (거리)**

#### 정의
$$D_{KL}(P \| Q) = \sum_x P(x) \log \frac{P(x)}{Q(x)}$$

**연속**:
$$D_{KL}(p \| q) = \int p(x) \log \frac{p(x)}{q(x)} \, dx$$

**크로스 엔트로피와의 관계**:
$$D_{KL}(P \| Q) = H(P, Q) - H(P)$$

또는:
$$H(P, Q) = H(P) + D_{KL}(P \| Q)$$

**의미**:
- $P$를 $Q$로 근사할 때 추가로 필요한 비트 수
- 분포 간 "정보적 거리"
- $Q$를 사용할 때의 비효율성

**성질**:
- $D_{KL}(P \| Q) \geq 0$ (항상 비음수)
- $D_{KL}(P \| Q) = 0 \Leftrightarrow P = Q$
- **비대칭**: $D_{KL}(P \| Q) \neq D_{KL}(Q \| P)$
- 진짜 거리(metric)는 아님 (삼각부등식 불만족)

---

### 3.4 머신러닝과의 연결

**손실함수로서의 크로스 엔트로피**:

분류 문제에서 모델을 학습시킬 때:
$$\text{Loss} = -\frac{1}{N} \sum_{i=1}^N \log Q(y_i | x_i)$$

이는 경험적 분포 $\hat{P}$와 모델 분포 $Q$의 크로스 엔트로피!

**핵심 등식**:

$$\min \text{NLL} = \min H(\hat{P}, Q) = \min [H(\hat{P}) + D_{KL}(\hat{P} \| Q)]$$

$H(\hat{P})$는 상수이므로:

$$\min H(\hat{P}, Q) \Leftrightarrow \min D_{KL}(\hat{P} \| Q)$$

**결론**:
> **크로스 엔트로피 최소화 = KL 다이버전스 최소화 = 모델 분포를 실제 분포에 근사**

---

### 3.5 상호 정보 (Mutual Information)
**두 변수가 공유하는 정보량**

#### 정의
$$I(X; Y) = \sum_{x,y} p(x,y) \log \frac{p(x,y)}{p(x)p(y)}$$

**연속**:
$$I(X; Y) = \int \int p(x,y) \log \frac{p(x,y)}{p(x)p(y)} \, dx \, dy$$

**다른 표현**:
$$I(X; Y) = H(X) - H(X|Y) = H(Y) - H(Y|X)$$

$$I(X; Y) = H(X) + H(Y) - H(X, Y)$$

**KL 다이버전스로 표현**:
$$I(X; Y) = D_{KL}(p(x,y) \| p(x)p(y))$$

**의미**:
- $Y$를 관찰했을 때 $X$의 불확실성이 얼마나 줄어드는가
- 실제 결합분포와 독립 가정의 차이
- 두 변수의 의존성 강도

**성질**:
- $I(X; Y) \geq 0$ (항상 비음수)
- $I(X; Y) = 0 \Leftrightarrow$ $X$와 $Y$ 독립
- **대칭**: $I(X; Y) = I(Y; X)$
- $I(X; X) = H(X)$ (자기 자신과의 상호정보는 엔트로피)

**예시**:
- 독립: 주사위 두 개 → $I(X; Y) = 0$
- 완전 종속: $Y = X$ → $I(X; Y) = H(X)$
- 부분 종속: 비와 우산 → $I > 0$

**응용**:
- 특징 선택 (feature selection)
- 변수 간 의존성 측정
- 정보 병목 (information bottleneck)

---

### 3.6 조건부 엔트로피 (Conditional Entropy)

**$Y$를 알 때 $X$의 불확실성**:

$$H(X|Y) = -\sum_{x,y} p(x,y) \log p(x|y) = \sum_y p(y) H(X|Y=y)$$

**연쇄 법칙 (Chain Rule)**:
$$H(X, Y) = H(X) + H(Y|X) = H(Y) + H(X|Y)$$

**성질**:
- $H(X|Y) \leq H(X)$ (정보는 불확실성을 줄임)
- 등호: $X$와 $Y$ 독립
- $I(X; Y) = H(X) - H(X|Y)$ (상호정보와 연결)

---
## 4. 대수·부등식·수렴·극한정리

---

### 4.1 기댓값과 분산의 성질

#### 기댓값의 선형성
$$\mathbb{E}[aX + b] = a\mathbb{E}[X] + b$$

$$\mathbb{E}[X + Y] = \mathbb{E}[X] + \mathbb{E}[Y]$$ 
(항상 성립, 독립 불필요)

#### 분산의 성질
$$\text{Var}(aX + b) = a^2 \text{Var}(X)$$

**합의 분산**:
$$\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y) + 2\text{Cov}(X, Y)$$

**독립일 때**:
$$\text{Var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \text{Var}(X_i)$$

#### 기댓값의 곱 (독립일 때만)
$$\mathbb{E}[XY] = \mathbb{E}[X]\mathbb{E}[Y] \quad \text{(X, Y 독립)}$$

---

### 4.2 확률 부등식

#### 4.2.1 마르코프 부등식 (Markov's Inequality)
비음수 확률변수에 대한 꼬리 확률 상한

**조건**: $X \geq 0$

$$P(X \geq a) \leq \frac{\mathbb{E}[X]}{a}, \quad a > 0$$

**의미**: 
- 기댓값이 작으면 큰 값이 나올 확률도 작다
- 매우 느슨한 상한이지만 널리 적용 가능

**예시**: 
- 평균 소득 $\mathbb{E}[X] = 50$만원
- $P(X \geq 100) \leq 50/100 = 0.5$ (50% 이하)

---

#### 4.2.2 체비셰프 부등식 (Chebyshev's Inequality)
평균 주변 확률 집중도

$$P(|X - \mu| \geq k\sigma) \leq \frac{1}{k^2}$$

또는:
$$P(|X - \mu| \geq \epsilon) \leq \frac{\text{Var}(X)}{\epsilon^2}$$

**의미**:
- 평균에서 $k$ 표준편차 이상 떨어질 확률은 $1/k^2$ 이하
- 분산이 작을수록 평균 근처에 집중

**예시**:
- $k=2$: $P(|X - \mu| \geq 2\sigma) \leq 1/4 = 25\%$
- $k=3$: $P(|X - \mu| \geq 3\sigma) \leq 1/9 \approx 11\%$

**특징**:
- 분포 무관 (어떤 분포든 적용)
- 마르코프보다 정밀 (분산 정보 활용)

---

#### 4.2.3 옌센 부등식 (Jensen's Inequality)
볼록/오목 함수의 기댓값

**볼록함수** $\phi$ (convex):
$$\phi(\mathbb{E}[X]) \leq \mathbb{E}[\phi(X)]$$

**오목함수** $\phi$ (concave):
$$\phi(\mathbb{E}[X]) \geq \mathbb{E}[\phi(X)]$$

**기하적 의미**:
- 평균을 먼저 취하고 함수 적용 vs 함수 적용 후 평균
- 볼록함수는 선분이 곡선 아래

**예시**:
- $\phi(x) = x^2$ (볼록): $(\mathbb{E}[X])^2 \leq \mathbb{E}[X^2]$
- $\phi(x) = \log x$ (오목): $\log(\mathbb{E}[X]) \geq \mathbb{E}[\log X]$

**응용**:
- KL 다이버전스 비음수 증명
- 변분 추론의 ELBO 유도
- AM-GM 부등식

---

### 4.3 확률적 수렴

#### 수렴 종류

**1. 확률 수렴 (Convergence in Probability)**
$$X_n \xrightarrow{P} X \Leftrightarrow \lim_{n \to \infty} P(|X_n - X| > \epsilon) = 0, \quad \forall \epsilon > 0$$

**2. 분포 수렴 (Convergence in Distribution)**
$$X_n \xrightarrow{d} X \Leftrightarrow \lim_{n \to \infty} F_n(x) = F(x), \quad \text{(연속점에서)}$$

**3. 거의 확실한 수렴 (Almost Sure Convergence)**
$$X_n \xrightarrow{a.s.} X \Leftrightarrow P(\lim_{n \to \infty} X_n = X) = 1$$

**관계**: 거의 확실한 수렴 ⇒ 확률 수렴 ⇒ 분포 수렴

---

### 4.4 대수의 법칙 (Law of Large Numbers, LLN)

독립동일분포(i.i.d.) $X_1, X_2, \ldots$ with $\mathbb{E}[X_i] = \mu$, $\text{Var}(X_i) = \sigma^2 < \infty$

**표본평균**:
$$\bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i$$

#### 약한 대수의 법칙 (Weak LLN)
$$\bar{X}_n \xrightarrow{P} \mu$$

**의미**: 표본 크기가 커질수록 표본평균이 모평균에 확률적으로 수렴

#### 강한 대수의 법칙 (Strong LLN)
$$\bar{X}_n \xrightarrow{a.s.} \mu$$

**의미**: 표본평균이 거의 확실하게 모평균으로 수렴

**실용적 해석**:
- 시행 횟수를 늘리면 평균이 안정됨
- 몬테카를로 시뮬레이션의 이론적 근거

---

### 4.5 중심극한정리 (Central Limit Theorem, CLT)

독립동일분포(i.i.d.) $X_1, X_2, \ldots$ with $\mathbb{E}[X_i] = \mu$, $\text{Var}(X_i) = \sigma^2 < \infty$

#### 정규화된 표본평균
$$Z_n = \frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}} = \frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma}$$

#### 정리
$$Z_n \xrightarrow{d} \mathcal{N}(0, 1) \quad \text{as } n \to \infty$$

또는:

$$\bar{X}_n \xrightarrow{d} \mathcal{N}\left(\mu, \frac{\sigma^2}{n}\right)$$

**의미**:
- **원래 분포와 무관**하게 표본평균은 정규분포로!
- $n$이 클수록 정규성 강해짐
- 일반적으로 $n \geq 30$이면 적용 가능

**실용적 의미**:
- 복잡한 분포 → 합/평균은 정규 근사 가능
- 통계적 추론(검정, 신뢰구간)의 기초
- 왜 정규분포가 자주 나타나는가의 이유

**예시**:
- 주사위 여러 개의 합
- 측정 오차의 누적
- 금융 수익률의 합

---

### 4.6 주요 정리 비교

| 정리 | 수렴 대상 | 결과 | 의미 |
|------|----------|------|------|
| **대수의 법칙** | $\bar{X}_n$ | $\mu$ | 평균값 자체로 수렴 |
| **중심극한정리** | $\frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}$ | $\mathcal{N}(0,1)$ | 분포 모양이 정규분포로 |

---

### 4.7 델타 방법 (Delta Method)

함수 변환에 대한 근사적 분포

$X_n \xrightarrow{d} \mathcal{N}(\mu, \sigma^2/n)$이고 $g$가 미분 가능하면:

$$g(X_n) \xrightarrow{d} \mathcal{N}\left(g(\mu), \frac{[g'(\mu)]^2 \sigma^2}{n}\right)$$

**용도**: 비선형 변환의 표본분포 근사

---

