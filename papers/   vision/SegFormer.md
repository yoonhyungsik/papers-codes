# ğŸ“˜ [SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers]

## 1. ê°œìš” (Overview)

* **ì œëª©**: SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers  
* **ì €ì**: Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo  
* **ì†Œì†**: The Chinese University of Hong Kong, NVIDIA, Caltech  
* **í•™íšŒ**: NeurIPS 2021  
* **ë§í¬**: [arXiv](https://arxiv.org/abs/2105.15203) / [GitHub](https://github.com/NVlabs/SegFormer) / [Papers with Code](https://paperswithcode.com/paper/segformer-simple-and-efficient-design-for)


> ë…¼ë¬¸ ì„ ì • ì´ìœ  ë° ê°„ë‹¨í•œ ë„ì…ë¶€ ì‘ì„±

ìµœê·¼ Vision Transformer(ViT)ì˜ ë“±ì¥ì€ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ë„˜ì–´ ë‹¤ì–‘í•œ ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ë¡œ í™•ì¥ë˜ê³  ìˆë‹¤. ê·¸ëŸ¬ë‚˜ semantic segmentationê³¼ ê°™ì€ dense prediction taskì— Transformerë¥¼ ì ìš©í•˜ëŠ” ë°ì—ëŠ” ì—¬ì „íˆ ê³„ì‚°ëŸ‰, êµ¬ì¡° ë³µì¡ì„±, positional encoding ì˜ì¡´ì„± ë“±ì˜ ì—¬ëŸ¬ ì œì•½ì´ ì¡´ì¬í•œë‹¤.

ì´ ë…¼ë¬¸ì€ ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ ì **íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ëª¨ë‘ ê³ ë ¤í•œ ìƒˆë¡œìš´ êµ¬ì¡°ì˜ segmentation ëª¨ë¸, SegFormerë¥¼ ì œì•ˆ**í•˜ì˜€ë‹¤. íŠ¹íˆ CNN ê¸°ë°˜ ë°±ë³¸ ì—†ì´ë„ ê³„ì¸µì  feature í‘œí˜„ì„ Transformerë¡œ ì§ì ‘ êµ¬ì„±í•˜ë©°, MLP ê¸°ë°˜ì˜ ë‹¨ìˆœí•œ decoder êµ¬ì¡°ë¡œë„ ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ëŠ” ì ì´ í¥ë¯¸ë¡­ë‹¤.

### ğŸ“Œ ì„ ì • ì´ìœ 
- **Transformer ê¸°ë°˜ êµ¬ì¡°**ì„ì—ë„ **ê³„ì¸µì  íŠ¹ì„±ê³¼ ì—°ì‚° íš¨ìœ¨ì„±**ì„ ë™ì‹œì— ë‹¬ì„±
- ë³µì¡í•œ decoder ì—†ì´ë„ SOTA ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë³´ì´ëŠ” **ë‹¨ìˆœí•œ MLP decoder ì„¤ê³„**
- **Positional Encoding ì—†ì´ë„** ê°•ë ¥í•œ ì„±ëŠ¥ ë‹¬ì„± â†’ ViTì˜ êµ¬ì¡°ì  í•œê³„ë¥¼ ë„˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì£¼ëª©

SegFormerëŠ” Vision Transformerì˜ êµ¬ì¡°ì  ìœ ì—°ì„±ì„ semantic segmentationì— ì„±ê³µì ìœ¼ë¡œ í™•ì¥í•œ ì‚¬ë¡€ë¡œ, **í–¥í›„ ê²½ëŸ‰í™”ëœ Transformer ëª¨ë¸ ì„¤ê³„ì— ìˆì–´ ì¤‘ìš”í•œ ì°¸ê³ ê°€ ë  ìˆ˜ ìˆë‹¤.**

---

## 2. ë¬¸ì œ ì •ì˜ (Problem Formulation)

**ë¬¸ì œ ë° ê¸°ì¡´ í•œê³„**:

**ViT ê¸°ë°˜ segmentation ëª¨ë¸ì˜ ë¬¸ì œì **
  - ViTëŠ” ì…ë ¥ì„ ê³ ì •ëœ í¬ê¸°ì˜ patchë¡œ ë‚˜ëˆ„ê³ , ë‹¨ì¼ í•´ìƒë„ì˜ feature mapë§Œ ìƒì„±í•¨.
  - **ë‹¨ì¼ ìŠ¤ì¼€ì¼ ì¶œë ¥**ìœ¼ë¡œ ì¸í•´ ë‹¤ì–‘í•œ í•´ìƒë„ ì •ë³´ ë¶€ì¡± (fine + coarse feature ë³‘í•© ë¶ˆê°€).
  - ë†’ì€ ì—°ì‚° ë¹„ìš© â†’ ëŒ€ê·œëª¨ ì…ë ¥ ì´ë¯¸ì§€ì— ë¹„íš¨ìœ¨ì .
  - **Positional Encoding**ì— ì˜ì¡´ â†’ ì…ë ¥ í•´ìƒë„ê°€ ë³€ê²½ë˜ë©´ ì„±ëŠ¥ ì €í•˜ ë°œìƒ.
**Decoder ì„¤ê³„ì˜ ì†Œí™€í•¨**
   - ëŒ€ë¶€ë¶„ì˜ ì—°êµ¬ê°€ encoder êµ¬ì¡°ì— ì§‘ì¤‘.
   - ë³µì¡í•˜ê±°ë‚˜ ë¬´ê±°ìš´ decoder êµ¬ì¡° ë˜ëŠ” CNN decoderë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ê°€ ë§ìŒ.
   - encoderê°€ ìƒì„±í•œ featureë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ì§€ ëª»í•¨.

**ì œì•ˆ ë°©ì‹**:
**Positional Encoding ì—†ì´ë„ ì„±ëŠ¥ì´ ì¢‹ì€ ê³„ì¸µì  Transformer Encoder**
   - positional embedding ì œê±° â†’ ë‹¤ì–‘í•œ í•´ìƒë„ì—ì„œë„ ì•ˆì •ì  ë™ì‘
   - ë¡œì»¬-ê¸€ë¡œë²Œ ì •ë³´ë¥¼ ëª¨ë‘ í¬ì°©í•  ìˆ˜ ìˆë„ë¡ **ê³„ì¸µì  (pyramid-like) êµ¬ì¡°** ì±„íƒ

**ê²½ëŸ‰í™”ëœ All-MLP Decoder**
   - ë³µì¡í•œ ëª¨ë“ˆ ì—†ì´ multi-scale featureë¥¼ ê°„ë‹¨í•œ MLPë¡œ ê²°í•©
   - Transformerì˜ ë‹¤ì–‘í•œ layerì—ì„œ ì–»ì€ local-global attention ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©

> â€» **í•µì‹¬ ê°œë… ì •ì˜ (ì˜ˆ: Masked LM, Next Sentence Prediction ë“±)**
| ê°œë… | ì„¤ëª… |
|------|------|
| **Hierarchical Transformer Encoder** | ê³ í•´ìƒë„ì—ì„œ ì €í•´ìƒë„ë¡œ ì´ì–´ì§€ëŠ” multi-scale êµ¬ì¡°. ê° ë‹¨ê³„ëŠ” Transformer layerë¡œ êµ¬ì„±ë˜ì–´ ìˆê³ , positional encodingì´ ì—†ìŒ. |
| **All-MLP Decoder** | multi-scale featureë“¤ì„ ê° í•´ìƒë„ì— ë§ê²Œ upsample í›„, MLPë¥¼ í†µí•´ ë³‘í•©í•˜ëŠ” ê°„ë‹¨í•œ êµ¬ì¡°. ë³µì¡í•œ convolution ëª¨ë“ˆ ì—†ì´ë„ ì„±ëŠ¥ í™•ë³´. |
| **Positional Encoding Free** | ìœ„ì¹˜ ì •ë³´ë¥¼ í•™ìŠµì— ì§ì ‘ì ìœ¼ë¡œ ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©°, êµ¬ì¡°ì ìœ¼ë¡œ local-global ì •ë³´ë¥¼ ë³‘í•©í•¨ìœ¼ë¡œì¨ ì´ë¥¼ ëŒ€ì²´. |
---

## 3. ëª¨ë¸ êµ¬ì¡° (Architecture)

### ì „ì²´ êµ¬ì¡°

![segformer_architecture](/papers/images/segformer_architecture.png)

SegFormerëŠ” Vision Transformerì˜ ê°•ì ì„ í™œìš©í•˜ë˜, ê¸°ì¡´ì˜ ViT ê¸°ë°˜ segmentation ëª¨ë¸ë“¤ì´ ê°€ì§„ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ **ê³„ì¸µì  multi-scale encoder**ì™€ **ê²½ëŸ‰í™”ëœ MLP ê¸°ë°˜ decoder**ë¡œ êµ¬ì„±ëœ êµ¬ì¡°ë¥¼ ì œì•ˆí•œë‹¤.

---

### ğŸ’  í•µì‹¬ êµ¬ì„± ìš”ì†Œ ë° ì‘ë™ ë°©ì‹

#### ğŸ“Œ Hierarchical Transformer Encoder

SegFormerì˜ encoderëŠ” ViT êµ¬ì¡°ë¥¼ ê³„ì¸µí™”(hierarchical)í•œ í˜•íƒœë¡œ, ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ë‹¨ê³„ë³„ë¡œ downsampling í•˜ë©° **multi-scale token feature**ë¥¼ ìƒì„±í•œë‹¤. ê° ë‹¨ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ í¬í•¨í•œë‹¤:

- **Overlapping Patch Embedding**  
  ê° ì…ë ¥ ì´ë¯¸ì§€ë¥¼ kernel size $3 \times 3$, stride $2$, padding $1$ì¸ convolutionìœ¼ë¡œ ë¶„í• í•˜ê³ , Linear projectionì„ í†µí•´ tokenìœ¼ë¡œ ë³€í™˜í•œë‹¤.

  $$z^0 = \text{Conv}_{3\times3}(x)$$

- **Transformer Block ë°˜ë³µ**  
  ê° ìŠ¤í…Œì´ì§€ë§ˆë‹¤ $L_i$ê°œì˜ Transformer blockì´ ì¡´ì¬í•˜ë©°, ê° blockì€ ë‹¤ìŒ ì—°ì‚°ìœ¼ë¡œ êµ¬ì„±ëœë‹¤:

$$
\begin{aligned}
z' &= \text{MSA}(\text{LN}(z)) + z \\
z^{\text{out}} &= \text{MLP}(\text{LN}(z')) + z'
\end{aligned}
$$


  ì—¬ê¸°ì„œ MSAëŠ” Multi-head Self-Attention, MLPëŠ” ë‘ ê°œì˜ Linear layerì™€ GELU í™œì„±í™” í•¨ìˆ˜ë¡œ êµ¬ì„±ëœë‹¤.

- **Downsampling between stages**  
  ê° ìŠ¤í…Œì´ì§€ ì‚¬ì´ì—ëŠ” resolutionì„ ì¤„ì´ê³  ì±„ë„ ìˆ˜ë¥¼ ëŠ˜ë¦¬ê¸° ìœ„í•œ **patch merging** ì—°ì‚°ì´ ìˆ˜í–‰ëœë‹¤.

**ì´ 4ê°œì˜ ìŠ¤í…Œì´ì§€**ì—ì„œ ê°ê° ë‹¤ìŒê³¼ ê°™ì€ í•´ìƒë„ì™€ ì±„ë„ ìˆ˜ë¥¼ ìƒì„±:

| Stage | Resolution                | Channels |
|-------|---------------------------|----------|
| 1     | $\frac{H}{4} \times \frac{W}{4}$   | 64       |
| 2     | $\frac{H}{8} \times \frac{W}{8}$   | 128      |
| 3     | $\frac{H}{16} \times \frac{W}{16}$ | 320      |
| 4     | $\frac{H}{32} \times \frac{W}{32}$ | 512      |

**Positional Encoding ì œê±°**:  
SegFormerëŠ” positional embeddingì„ ì œê±°í•˜ê³ , self-attention êµ¬ì¡° ìì²´ì—ì„œ ê³µê°„ ê´€ê³„ë¥¼ í•™ìŠµí•˜ê²Œ í•¨ìœ¼ë¡œì¨ **í•´ìƒë„ ë…ë¦½ì ** ì„±ëŠ¥ì„ ë³´ì¥í•œë‹¤.

---

#### ğŸ“Œ All-MLP Decoder

SegFormerì˜ decoderëŠ” convolution ë˜ëŠ” attention ì—°ì‚° ì—†ì´, ê° ìŠ¤í…Œì´ì§€ì˜ featureë¥¼ ë‹¨ìˆœ upsampleí•˜ê³  MLPë¡œ ê²°í•©í•˜ëŠ” **ë§¤ìš° ë‹¨ìˆœí•œ êµ¬ì¡°**ì´ë‹¤.

##### êµ¬ì„± ë‹¨ê³„:

1. **Feature Upsampling**:  
   ê° ìŠ¤í…Œì´ì§€ì—ì„œ ë‚˜ì˜¨ feature $F_i$ë¥¼ ë™ì¼ í•´ìƒë„(1/4 resolution)ë¡œ bilinear upsamplingí•œë‹¤:

   $$\hat{F}_i = \text{Upsample}(F_i) \quad \text{for } i = 1,2,3,4$$

2. **Feature Concatenation & MLP**:  
   Upsampleëœ featureë“¤ì„ ì±„ë„ ì°¨ì›ìœ¼ë¡œ concatí•œ í›„, linear projectionì„ ìˆ˜í–‰í•œë‹¤:
   
$$
F_{\text{concat}} = \text{Concat}(\hat{F}_1, \hat{F}_2, \hat{F}_3, \hat{F}_4)
$$

$$
y = \text{MLP}(F_{\text{concat}})
$$


4. **Segmentation Output**:  
   ìµœì¢…ì ìœ¼ë¡œ segmentation mapìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ 1Ã—1 conv í›„ ì›ë˜ í•´ìƒë„ë¡œ upsampleí•œë‹¤.

##### ì™œ All-MLPì¸ê°€?

- encoderì—ì„œ ì´ë¯¸ richí•œ í‘œí˜„ì„ ì–»ì—ˆê¸° ë•Œë¬¸ì— ë³µì¡í•œ decoder êµ¬ì¡°ê°€ í•„ìš” ì—†ìŒ
- ë‚®ì€ ë ˆì´ì–´ëŠ” local ì •ë³´, ë†’ì€ ë ˆì´ì–´ëŠ” global ì •ë³´ë¥¼ ê°–ê³  ìˆì–´ ë‹¨ìˆœ MLPë¡œ ê²°í•©í•´ë„ ì¶©ë¶„

---

### ğŸ“Œ êµ¬ì¡°ì  ì„¤ê³„ ì² í•™

SegFormerëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì² í•™ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆë‹¤:

| ìš”ì†Œ | ê¸°ì¡´ ë°©ë²• (SETR, PVT ë“±) | SegFormer |
|------|--------------------------|-----------|
| Encoder êµ¬ì¡° | ë‹¨ì¼ í•´ìƒë„ ViT | ê³„ì¸µì  Transformer (multi-scale) |
| Positional Encoding | í•„ìˆ˜ | ì œê±° |
| Decoder | ë³µì¡í•œ CNN / ASPP | All-MLP (ë¹„êµì  ë‹¨ìˆœ) |
| í•´ìƒë„ ëŒ€ì‘ | ë‚®ìŒ | í•´ìƒë„ ë³€í™”ì— ê°•ê±´ |
| ë¡œì»¬-ê¸€ë¡œë²Œ ë¶„ë¦¬ | ë¶ˆëª…í™• | ê³„ì¸µì  attentionìœ¼ë¡œ ë¶„ë¦¬ |

---

### ğŸ”¬ ê°œë… ìš”ì•½

- **ëŠ”ë‹¤.

## ğŸ”§ Step 1: TransformerëŠ” ì™œ ìœ„ì¹˜ ì •ë³´ë¥¼ ëª» ì•Œì•„ë³´ëŠ”ê°€?

### ğŸ’¡ í•µì‹¬ ê°œë…

Transformerì˜ **self-attentionì€ permutation-invariant** (ìˆœì„œë¥¼ ë¬´ì‹œí•˜ëŠ” ì—°ì‚°).

- Attentionì€ ëª¨ë“  í† í°(ë˜ëŠ” íŒ¨ì¹˜) ê°„ì˜ ê´€ê³„ë¥¼ **ìœ„ì¹˜ ì •ë³´ ì—†ì´** ê³„ì‚°í•œë‹¤.
- ë”°ë¼ì„œ ì´ë¯¸ì§€ íŒ¨ì¹˜ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ë‚˜ì—´í•˜ë©´, ëª¨ë¸ì€ ì´ê²Œ â€œì™¼ìª½ ê·€â€ì¸ì§€ â€œì˜¤ë¥¸ìª½ ê¼¬ë¦¬â€ì¸ì§€ **êµ¬ë¶„í•  ìˆ˜ ì—†ë‹¤**.

> ğŸ“Œ ê·¸ë˜ì„œ **ViTëŠ” positional encodingì„ ê° patchì— ë”í•´**,  
> â€œì´ patchëŠ” ì´ë¯¸ì§€ì˜ ì–´ë””ì¯¤ì— ìˆì—ˆë‹¤â€ëŠ” ì •ë³´ë¥¼ **ëª…ì‹œì ìœ¼ë¡œ ì£¼ì…**.

---

## ğŸ”§ Step 2: ViTì˜ Patch Embedding êµ¬ì¡°

ViTëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ í†µí•´ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬:

1. ì´ë¯¸ì§€ë¥¼ **16Ã—16 í¬ê¸°ì˜ non-overlapping patch**ë¡œ ìë¥¸ë‹¤.
2. ê° patchë¥¼ **flatten**í•œ ë’¤, Linear Layerì— ë„£ì–´ token embeddingì„ ë§Œë“ ë‹¤.
3. ì´ë•Œ **ê³µê°„ ì •ë³´ê°€ ì™„ì „íˆ ì‚¬ë¼ì§€ê¸° ë•Œë¬¸ì—**, positional encodingì„ ì¶”ê°€ë¡œ ë”í•œë‹¤.


> ğŸ“Œ ViTì˜ êµ¬ì¡°ì—ì„œëŠ” patch ìì²´ì—ëŠ” ìœ„ì¹˜ ì •ë³´ê°€ ì—†ê¸° ë•Œë¬¸ì—  
> **positional encodingì´ ë°˜ë“œì‹œ í•„ìš”**.

---

## ğŸ”§ Step 3: SegFormerì˜ Overlapping Patch Embedding êµ¬ì¡°

SegFormerëŠ” ViTì™€ ë‹¬ë¦¬, patchë¥¼ ìë¥´ì§€ ì•Šê³  **Conv2D ì—°ì‚°ì„ í†µí•´ patchë¥¼ ìƒì„±**.

### ğŸ¯ Overlapping Patch Embedding ë°©ì‹

- `Conv2D(kernel=3, stride=2, padding=1)`ì„ ì‚¬ìš©í•´ feature embeddingì„ ìƒì„±.
- ì´ ì—°ì‚°ì€ 3Ã—3 í¬ê¸°ì˜ í•„í„°ë¥¼ **ê²¹ì¹˜ë©´ì„œ(overlapping)** ì ìš©.
- ì¦‰, patchë¥¼ ë§Œë“œëŠ” ë™ì‹œì— **local context (ìœ„ì¹˜ ì£¼ë³€ ì •ë³´)**ë¥¼ í•¨ê»˜ ë´„.
ì˜ˆì‹œ:
patch_1 â†’ ì£¼ë³€ 3Ã—3 ì˜ì—­ ë³´ê¸° (ì¢Œìš° í”½ì…€ í¬í•¨)
patch_2 â†’ patch_1ê³¼ í”½ì…€ ì¼ë¶€ ê³µìœ 


---

### ğŸ“Œ ì´ ë°©ì‹ì˜ íš¨ê³¼

- patchë“¤ì´ ì„œë¡œ ê²¹ì³ ìˆìœ¼ë¯€ë¡œ, ì¸ì ‘í•œ patchê°€ **ê°™ì€ í”½ì…€ ì¼ë¶€ë¥¼ ê³µìœ ** í•œë‹¤.
- ì´ë¡œ ì¸í•´ patch ê°„ì˜ **ê³µê°„ ì—°ì†ì„±(spatial continuity)**ê°€ ìœ ì§€ëœë‹¤.
- ë˜í•œ Conv ì—°ì‚°ì€ **ìœ„ì¹˜ì— ë”°ë¼ ë‹¤ë¥¸ ê°’ì„ ì¶œë ¥**í•˜ê¸° ë•Œë¬¸ì—,  
  ëª¨ë¸ì€ **ì´ featureê°€ ì´ë¯¸ì§€ ì–´ë””ì—ì„œ ì™”ëŠ”ì§€ë¥¼ ë‚´ì¬ì ìœ¼ë¡œ êµ¬ë³„**í•  ìˆ˜ ìˆë‹¤.

> âœ… ê²°ê³¼ì ìœ¼ë¡œ, Conv2Dë¡œ ë§Œë“  patchëŠ” ë‹¨ìˆœí•œ ìƒ‰ìƒ ì •ë³´ë§Œ ë‹´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼  
> **í˜•íƒœ ì •ë³´ + ìœ„ì¹˜ ì •ë³´**ë¥¼ í•¨ê»˜ ë‚´í¬í•˜ê²Œ ë¨.

---

## âœ… ê²°ë¡ 

SegFormerëŠ” **patch ìƒì„± ë‹¨ê³„ì—ì„œë¶€í„° ìœ„ì¹˜ ì •ë³´ë¥¼ ìœ ì§€í•˜ëŠ” êµ¬ì¡°**ë¥¼ ì‚¬ìš©í•œë‹¤.  
ë”°ë¼ì„œ ViTì²˜ëŸ¼ ë³„ë„ë¡œ positional encodingì„ ë”í•˜ì§€ ì•Šì•„ë„,  
**êµ¬ì¡°ì ìœ¼ë¡œ ìœ„ì¹˜ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆëŠ” inductive bias**ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë‚´ì¥ë˜ì–´ ìˆë‹¤.

> ì¦‰, **Overlapping Patch Embeddingì€ ìœ„ì¹˜ ì •ë³´ë¥¼ 'ì•”ë¬µì ìœ¼ë¡œ í¬í•¨í•œ' embedding ë°©ì‹ì´ë©°,  
> ì´ê²ƒì´ positional encodingì„ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ê·¼ê±°ë‹¤.**



---

## âš–ï¸ ê¸°ì¡´ ëª¨ë¸ê³¼ì˜ ë¹„êµ

| í•­ëª©         | SegFormer (ë³¸ ë…¼ë¬¸)                     | SETR (ViT ê¸°ë°˜)                 | DeepLabV3+ (CNN ê¸°ë°˜)      |
|--------------|------------------------------------------|----------------------------------|-----------------------------|
| êµ¬ì¡°         | Hierarchical Transformer + All-MLP       | Flat ViT + CNN decoder           | ResNet backbone + ASPP      |
| í•™ìŠµ ë°©ì‹    | Positional Encoding ì—†ìŒ, multi-scale   | Positional Encoding ìˆìŒ, ë‹¨ì¼ scale | CNN ê¸°ë°˜ End-to-End       |
| ëª©ì          | ê²½ëŸ‰í™” + ì •í™•ë„ + í•´ìƒë„ ìœ ì—°ì„±           | Transformer ì„±ëŠ¥ í™•ì¸ ì¤‘ì‹¬         | ê³ ì • í•´ìƒë„ì—ì„œ ì„±ëŠ¥ ìµœì í™” |

---

## ğŸ“‰ ì‹¤í—˜ ë° ê²°ê³¼

* **ë°ì´í„°ì…‹**:
  - ADE20K
  - Cityscapes
  - COCO-Stuff

* **ë¹„êµ ëª¨ë¸**:
  - DeepLabV3+
  - SETR
  - Swin Transformer
  - PVT (Pyramid Vision Transformer)

* **ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ ë° ê²°ê³¼**:

| ëª¨ë¸            | mIoU (ADE20K) | mIoU (Cityscapes) | FPS (Cityscapes) | ëª¨ë¸ í¬ê¸° |
|-----------------|---------------|-------------------|------------------|------------|
| SegFormer-B0    | 37.4%         | 71.9%             | 48 FPS           | 3.7M       |
| SegFormer-B5    | **51.8%**     | **84.0%**         | 22 FPS           | 84.7M      |
| SETR-MLA        | 48.6%         | 79.3%             | < 5 FPS          | 308M       |
| DeepLabV3+      | ~45%          | ~78%              | 18â€“30 FPS        | >50M       |

> **ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ ë° í•´ì„**:  
> SegFormerëŠ” ê¸°ì¡´ ViT ê¸°ë°˜ ëª¨ë¸ë³´ë‹¤ í›¨ì”¬ ì ì€ ì—°ì‚°ëŸ‰ê³¼ íŒŒë¼ë¯¸í„°ë¡œë„ ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í•¨. íŠ¹íˆ ì‘ì€ ëª¨ë¸ì¸ B0ì€ **ICNet ëŒ€ë¹„ 60% ë¹ ë¥´ê³  4.2% ë” ë†’ì€ ì •í™•ë„**, í° ëª¨ë¸ì¸ B5ëŠ” SETRë³´ë‹¤ **1.8% ë” ë†’ì€ mIoUì™€ 5ë°° ë” ë¹ ë¥¸ ì†ë„**ë¥¼ ë³´ì¸ë‹¤.

---

## âœ… ì¥ì  ë° í•œê³„

### **ì¥ì **:

- **ê³„ì¸µì  Transformer êµ¬ì¡°**ë¥¼ í†µí•´ CNNì²˜ëŸ¼ multi-scale featureë¥¼ ìƒì„±í•¨
- **Positional Encoding ì—†ì´ë„ ê°•ë ¥í•œ ì„±ëŠ¥** í™•ë³´ (í•´ìƒë„ ë³€í™”ì— ê°•ê±´)
- **ê°„ë‹¨í•œ All-MLP Decoder**ë¡œ ì—°ì‚°ëŸ‰ì„ ì¤„ì´ë©´ì„œë„ SOTA ì„±ëŠ¥ ë‹¬ì„±
- ë‹¤ì–‘í•œ ì…ë ¥ í•´ìƒë„ì™€ ìƒí™©ì—ì„œë„ **ë²”ìš©ì„± ë†’ì€ ì„±ëŠ¥**
- ì‹¤ì œ inference ì†ë„(48 FPS, B0 ê¸°ì¤€)ê°€ ë¹ ë¥´ê³  ê²½ëŸ‰ ëª¨ë¸ë„ ì˜ ì‘ë™

---

### **í•œê³„ ë° ê°œì„  ê°€ëŠ¥ì„±**:

- Fully Transformer êµ¬ì¡°ì´ë¯€ë¡œ **pre-trainingì— ì˜ì¡´**í•˜ëŠ” ê²½í–¥ ìˆìŒ (ImageNet ë“±)
- ViTì™€ ë™ì¼í•˜ê²Œ **ë°ì´í„° ë¶€ì¡± í™˜ê²½ì—ì„œëŠ” í•™ìŠµ ì–´ë ¤ì›€**
- Decoderê°€ ë‹¨ìˆœ MLPì´ë¯€ë¡œ **ë³µì¡í•œ êµ¬ì¡°ë¥¼ ìš”êµ¬í•˜ëŠ” scene parsingì—ëŠ” í•œê³„ ê°€ëŠ¥ì„±**
- **Patch Embeddingì€ ê³ ì • resolution ê¸°ë°˜ì´ë¯€ë¡œ** ì•„ì£¼ ì‘ì€ ê°ì²´ í‘œí˜„ì€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ

---

## ğŸ§  TL;DR â€“ í•œëˆˆì— ìš”ì•½

> SegFormerëŠ” **Positional Encoding ì—†ì´ë„ ì„±ëŠ¥ì„ ìœ ì§€í•˜ëŠ” Hierarchical Transformer Encoder**ì™€ **ë³µì¡í•œ ì—°ì‚° ì—†ì´ë„ ê°•ë ¥í•œ í‘œí˜„ë ¥ì„ ì œê³µí•˜ëŠ” All-MLP Decoder**ë¥¼ ê²°í•©í•˜ì—¬, **íš¨ìœ¨ì„±, ì •í™•ë„, í•´ìƒë„ ì ì‘ì„±**ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì°¨ì„¸ëŒ€ semantic segmentation ëª¨ë¸ì„ ì œì•ˆí•œë‹¤.  
> íŠ¹íˆ, ê¸°ì¡´ Vision Transformer ê¸°ë°˜ segmentation ëª¨ë¸ë“¤ì˜ í•œê³„ì˜€ë˜ **ë‹¨ì¼ í•´ìƒë„ ì²˜ë¦¬, ê³ ì •ëœ positional encoding, ë†’ì€ ì—°ì‚°ëŸ‰**ì„ êµ¬ì¡°ì ìœ¼ë¡œ ê·¹ë³µí•˜ë©°, ê²½ëŸ‰ ëª¨ë¸(B0)ë¶€í„° ëŒ€í˜• ëª¨ë¸(B5)ê¹Œì§€ **SOTA ì„±ëŠ¥ê³¼ ë¹ ë¥¸ FPS**ë¥¼ ë™ì‹œì— ë‹¬ì„±í•œë‹¤.

---

| êµ¬ì„± ìš”ì†Œ    | ì„¤ëª… |
|-------------|------|
| í•µì‹¬ ëª¨ë“ˆ    | **Hierarchical Transformer Encoder** + **All-MLP Decoder** êµ¬ì¡°. CNNì²˜ëŸ¼ multi-scale feature ì¶”ì¶œ í›„, MLPë¡œ ê²°í•© |
| í•™ìŠµ ì „ëµ    | **End-to-End supervised learning** using ImageNet pre-trained weights, positional encoding ì—†ì´ë„ í•™ìŠµ ê°€ëŠ¥ |
| ì „ì´ ë°©ì‹    | ë‹¤ì–‘í•œ í•´ìƒë„ì™€ ì…ë ¥ í¬ê¸°ì—ì„œë„ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë³´ì´ë©°, ADE20K/Cityscapes/COCO-Stuff ë“±ìœ¼ë¡œ fine-tuning |
| ì„±ëŠ¥/íš¨ìœ¨ì„± | íŒŒë¼ë¯¸í„° ìˆ˜ì™€ ì—°ì‚°ëŸ‰ì„ ì¤„ì´ë©´ì„œë„ ê¸°ì¡´ SOTA ëª¨ë¸(DeepLabV3+, SETR ë“±) ëŒ€ë¹„ **ë” ë†’ì€ ì •í™•ë„ì™€ FPS** ë‹¬ì„± |

---

## ğŸ”— ì°¸ê³  ë§í¬ (References)

* [ğŸ“„ arXiv ë…¼ë¬¸](https://arxiv.org/abs/2105.15203)
* [ğŸ’» GitHub - NVlabs/SegFormer](https://github.com/NVlabs/SegFormer)
* [ğŸ“ˆ Papers with Code](https://paperswithcode.com/paper/segformer-simple-and-efficient-design-for)


## ë‹¤ìŒ ë…¼ë¬¸: SAM
