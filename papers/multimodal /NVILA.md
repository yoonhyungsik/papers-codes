# ğŸ“˜ NVILA: Efficient Frontier Visual Language Models

## 1. ê°œìš” (Overview)

* **ì œëª©**: NVILA: Efficient Frontier Visual Language Models  
* **ì €ì**: Zhijian Liu, Ligeng Zhu, Baifeng Shi, Zhuoyang Zhang, Yuming Lou, Shang Yang, ë“±  
* **ì†Œì†**: NVIDIA, MIT, Tsinghua University ë“± ì‚°í•™ í˜‘ë ¥íŒ€  
* **í•™íšŒ**: arXiv (2024ë…„ 12ì›”, Preprint)  
* **ë§í¬**: [arXiv](https://arxiv.org/abs/2412.04468) / [GitHub](https://github.com/NVILA-Team/NVILA) _(ì˜ˆì‹œ placeholder)_ / [Papers with Code](https://paperswithcode.com/paper/nvila-efficient-frontier-visual-language)

> ë³¸ ë…¼ë¬¸ì€ **ë©€í‹°ëª¨ë‹¬ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM)**ì˜ ìµœì‹  ì—°êµ¬ ì¤‘ í•˜ë‚˜ë¡œ, ë‹¨ìˆœ ì„±ëŠ¥ í–¥ìƒì—ë§Œ ì´ˆì ì„ ë§ì¶”ë˜ ê¸°ì¡´ VLMê³¼ ë‹¬ë¦¬ **íš¨ìœ¨ì„±ê³¼ ì •í™•ë„ì˜ ê· í˜•**ì„ ë§ì¶”ëŠ” ë° ì¤‘ì ì„ ë‘ .  
> NVILAëŠ” VILA ì•„í‚¤í…ì²˜ë¥¼ í™•ì¥í•˜ë©´ì„œë„ "scale-then-compress" ì „ëµì„ ë„ì…í•˜ì—¬ **ê³ í•´ìƒë„ ì´ë¯¸ì§€Â·ì¥ì‹œê°„ ë¹„ë””ì˜¤ ì²˜ë¦¬**ê°€ ê°€ëŠ¥í•˜ë©´ì„œë„, **í•™ìŠµ ë¹„ìš©ê³¼ ì¶”ë¡  ì§€ì—° ì‹œê°„ì„ í¬ê²Œ ì ˆê°**.  
> ë”°ë¼ì„œ ì—°êµ¬ ëª©ì ë¿ë§Œ ì•„ë‹ˆë¼ **ì‹¤ì œ ì‚°ì—… ì‘ìš© ê°€ëŠ¥ì„±**ì´ ë†’ë‹¤ëŠ” ì ì—ì„œ ë³¸ ë…¼ë¬¸ì„ ì„ ì •.

---

## 2. ë¬¸ì œ ì •ì˜ (Problem Formulation)

**ë¬¸ì œ ë° ê¸°ì¡´ í•œê³„**:

* ìµœì‹  Visual Language Model(VLM)ë“¤ì€ ì„±ëŠ¥(ì •í™•ë„) ìœ„ì£¼ë¡œ ì„¤ê³„ë˜ì–´, **ê³„ì‚° ë¹„ìš©ê³¼ ì¶”ë¡  ì§€ì—°(latency)**ì´ ì§€ë‚˜ì¹˜ê²Œ í¬ë‹¤ëŠ” ë¬¸ì œê°€ ìˆìŒ.  
* íŠ¹íˆ **ê³ í•´ìƒë„ ì´ë¯¸ì§€**ì™€ **ì¥ì‹œê°„ ë¹„ë””ì˜¤ ì…ë ¥**ì„ ì²˜ë¦¬í•  ë•Œ, ë¹„ì£¼ì–¼ í† í° ìˆ˜ê°€ í­ë°œì ìœ¼ë¡œ ì¦ê°€ â†’ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, í•™ìŠµ ë¹„ìš©, ì¶”ë¡  ì‹œê°„ì´ í¬ê²Œ ì¦ê°€.  
* ê¸°ì¡´ ë°©ì‹ì€ í† í° ì••ì¶•ì´ë‚˜ í•´ìƒë„ ì¶•ì†Œ ë“± ë‹¨ì¼ ì „ëµë§Œ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì—, **ì •ë³´ ì†ì‹¤** ë˜ëŠ” **íš¨ìœ¨ì„± ì €í•˜**ê°€ ë¶ˆê°€í”¼í–ˆìŒ.

---

**ì œì•ˆ ë°©ì‹ (NVILA)**:

* **Scale-Then-Compress ì „ëµ**:  
  - ë¨¼ì € ì´ë¯¸ì§€/ë¹„ë””ì˜¤ë¥¼ **ê³ í•´ìƒë„Â·ì¥ì‹œê°„ ìŠ¤ì¼€ì¼**ë¡œ í™•ì¥í•˜ì—¬ ì •ë³´ ë³´ì¡´ ê·¹ëŒ€í™”.  
  - ì´í›„ íš¨ìœ¨ì ì¸ **í† í° ì••ì¶•(token compression)**ì„ ì ìš©í•´ ë¶ˆí•„ìš”í•œ ì¤‘ë³µì„ ì œê±°í•˜ê³  ê³„ì‚°ëŸ‰ ì ˆê°.  
* í•™ìŠµ, ë¯¸ì„¸ì¡°ì •(fine-tuning), ì¶”ë¡  ë“± **ì „ì²´ ìƒì• ì£¼ê¸°(lifecycle)ì—ì„œ íš¨ìœ¨ì„± ê°œì„ **ì„ ë‹¬ì„±.  
* FP8 ì •ë°€ë„, dataset pruning, pre-filling ìµœì í™” ë“± ë‹¤ì–‘í•œ íš¨ìœ¨í™” ê¸°ë²•ì„ í†µí•©ì ìœ¼ë¡œ ì ìš©.  

---

> **í•µì‹¬ ê°œë… ì •ì˜**  
> - **Visual Token Compression**: ì´ë¯¸ì§€/ë¹„ë””ì˜¤ì—ì„œ ì¶”ì¶œëœ ë‹¤ìˆ˜ì˜ í† í°ì„ ìš”ì•½Â·ì••ì¶•í•˜ì—¬, ì •ë³´ëŠ” ìœ ì§€í•˜ë©´ì„œ ì—°ì‚°ëŸ‰ì„ ì¤„ì´ëŠ” ê³¼ì •.  
> - **Scale-Then-Compress**: ë¨¼ì € ë†’ì€ í•´ìƒë„Â·ì‹œê°„ì  ìŠ¤ì¼€ì¼ë¡œ ì…ë ¥ì„ ì²˜ë¦¬í•œ í›„, ë¹„ì£¼ì–¼ í† í°ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì••ì¶•í•˜ëŠ” NVILAì˜ í•µì‹¬ ì ‘ê·¼ë²•.  
> - **Pre-filling ë‹¨ê³„**: LLMì— ë¹„ì£¼ì–¼+ì–¸ì–´ í† í°ì„ ì…ë ¥í•˜ê¸° ì „ì— ì¤€ë¹„í•˜ëŠ” ì´ˆê¸°í™” ê³¼ì •ìœ¼ë¡œ, latency ìµœì í™”ì˜ ì£¼ìš” í¬ì¸íŠ¸.  


## 3. ëª¨ë¸ êµ¬ì¡° (Architecture)

### ì „ì²´ êµ¬ì¡°

![ëª¨ë¸ êµ¬ì¡°](../images/NVILA_architecture.png)

* **ì…ë ¥/ì „ì²˜ë¦¬**: ì´ë¯¸ì§€Â·ë¹„ë””ì˜¤ë¥¼ ë°›ì•„ **í•´ìƒë„/ì‹œê°„ ìŠ¤ì¼€ì¼ì„ ë¨¼ì € í™•ì¥(Scale)** í•œ ë’¤, **ê³µê°„/ì‹œê°„ í† í°ì„ ì••ì¶•(Compress)** í•˜ëŠ” íŒŒì´í”„ë¼ì¸. ì´ë¯¸ì§€ì˜ ê²½ìš° ë©€í‹°ìŠ¤ì¼€ì¼ íƒ€ì¼ë§(ì˜ˆ: 448Â², 896Â², 1344Â² ìŠ¤ì¼€ì¼ë¡œ ë¶„í• ) í›„ í•©ì¹˜ê³ , ë¹„ë””ì˜¤ëŠ” í”„ë ˆì„ ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤.
* **Visual Encoder (ViT/SigLIP)**: íƒ€ì¼/í”„ë ˆì„ ë‹¨ìœ„ë¡œ íŒ¨ì¹˜ ì„ë² ë”©ì„ ì¶”ì¶œ.  
* **Projector (2-layer MLP)**: ì‹œê° ì„ë² ë”©ì„ LLM ì„ë² ë”© ê³µê°„ìœ¼ë¡œ ì •ë ¬.   
* **Token Processor (LLM, Qwen2 ê³„ì—´)**: â€œí…ìŠ¤íŠ¸ í† í° + ì••ì¶•ëœ ë¹„ì£¼ì–¼ í† í°â€ì„ ë°›ì•„ ì˜¤í† ë¦¬ê·¸ë ˆì‹œë¸Œë¡œ ì–¸ì–´ í† í°ì„ ìƒì„±.  
* **í•µì‹¬ ì „ëµ**: â€œ**Scaleâ€‘thenâ€‘Compress**â€ â€” ë¨¼ì € ë” ë§ì€ ë””í…Œì¼ì„ ë³´ì¡´í•˜ë„ë¡ í•´ìƒë„/í”„ë ˆì„ì„ í‚¤ìš°ê³ , ì´í›„ í† í°ì„ ì¤„ì—¬ ì—°ì‚°ëŸ‰ì„ ì–µì œ. ê²°ê³¼ì ìœ¼ë¡œ ê³ í•´ìƒë„ ì´ë¯¸ì§€Â·ì¥ì‹œê°„ ë¹„ë””ì˜¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬.

---

### ğŸ’  í•µì‹¬ ëª¨ë“ˆ ë˜ëŠ” êµ¬ì„± ìš”ì†Œ

#### ğŸ“Œ Visual Encoder + Dynamicâ€‘S2 Tiling
* **ì‘ë™ ë°©ì‹**: S2ë¡œ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì—¬ëŸ¬ ìŠ¤ì¼€ì¼(ì˜ˆ: 448Â², 896Â², 1344Â²)ë¡œ ë¦¬ì‚¬ì´ì¦ˆ â†’ ê° ìŠ¤ì¼€ì¼ì„ 448Ã—448 íƒ€ì¼ë¡œ ë¶„í• í•´ ì¸ì½”ë”ì— í†µê³¼ â†’ ìŠ¤ì¼€ì¼ë³„ íŠ¹ì„±ë§µì„ ì¬ê²°í•©Â·ì±„ë„ ë°©í–¥ìœ¼ë¡œ ì»¨ìº£. ê¸°ë³¸ S2ëŠ” ì •ì‚¬ê°í˜•ìœ¼ë¡œ ê°•ì œí•´ ì¢…íš¡ë¹„ ì™œê³¡ì´ ë°œìƒí•  ìˆ˜ ìˆì–´, **Dynamicâ€‘S2**ëŠ” ìµœëŒ€ ìŠ¤ì¼€ì¼ì—ì„œ **ì›ë³¸ ì¢…íš¡ë¹„ë¥¼ ìœ ì§€**í•˜ë©´ì„œ 448 íƒ€ì¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ í¬ê¸°ë¥¼ ì„ íƒí•´ ì™œê³¡ì„ ì¤„ì¸ë‹¤.  
* **íš¨ê³¼**: í…ìŠ¤íŠ¸ê°€ ë§ì€ ì´ë¯¸ì§€ ë“±ì—ì„œ **ìµœëŒ€ â‰ˆ30% ì •í™•ë„ í–¥ìƒ**ì„ ë³´ê³ . ì´í›„ í† í° ì••ì¶• ë‹¨ê³„ë¡œ íš¨ìœ¨ì„ íšŒìˆ˜. 

> **êµ¬ì¡°ì  ê°œë…**  
> - S2 ë©€í‹°ìŠ¤ì¼€ì¼ í•©ì„±: ê° ìŠ¤ì¼€ì¼ì˜ íƒ€ì¼ íŠ¹ì„±ë§µì„ **ë™ì¼ í•´ìƒë„ë¡œ ë³´ê°„ â†’ ì±„ë„ concat**.  
> - Dynamicâ€‘S2: ìµœëŒ€ ìŠ¤ì¼€ì¼ë§Œ **ì¢…íš¡ë¹„ ë³´ì¡´ + 448 íƒ€ì¼ ë°°ì¹˜ê°€ ê°€ëŠ¥í•œ í•´ìƒë„**ë¡œ ì¡°ì •. 

---

#### ğŸ“Œ Spatial Token Compression (STC)
* **ì‘ë™ ë°©ì‹**: íƒ€ì¼ ë‚´ í† í° ê²©ìë¥¼ **kÃ—k ê³µê°„â†’ì±„ë„ ì¬ë°°ì—´(Spatialâ€‘toâ€‘Channel)**ë¡œ ì••ì¶•í•´ í† í° ê°œìˆ˜ë¥¼ **kÂ² ë°°** ì¤„ì„. ë…¼ë¬¸ì€ **2Ã—2 STC**ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¼ê³ , ë” ê³µê²©ì ì¸ **3Ã—3 STC**ëŠ” ì •í™•ë„ ì €í•˜ë¥¼ ìœ ë°œí•˜ë¯€ë¡œ **ì¶”ê°€ Visual Encoder Preâ€‘training(VEP)** ë‹¨ê³„ë¡œ **ì •í™•ë„ íšŒë³µ**(í›ˆë ¨/ì¶”ë¡  **â‰ˆ2.4Ã— ê°€ì†**)ì„ ë³´ê³ . 
* **ëŒ€ì•ˆ ë¹„êµ**: **TokenLearner**, **Perceiver Resampler** ê°™ì€ í•™ìŠµí˜• ì••ì¶•ë„ ì‹¤í—˜í–ˆìœ¼ë‚˜ **ë™ì¼ ì••ì¶•ë¹„ì—ì„œ ë‹¨ìˆœ STCê°€ ë™ë“±/ìš°ìˆ˜**í•œ ê²°ê³¼. (ìµœì í™” ì´ìŠˆë¡œ í•´ì„)

> **ìˆ˜ì‹/í† í° ìˆ˜ ê°œë…**  
> - (íƒ€ì¼ ê¸°ì¤€) **ì••ì¶• ì „ í† í° ìˆ˜**: $N_{\text{tile}}$  
> - **STC(kÃ—k) í›„**: $N_{\text{tile}}' \approx \frac{N_{\text{tile}}}{k^2}$  
> - í‘œ ì˜ˆì‹œ: **2Ã—2**ì—ì„œ íƒ€ì¼ë‹¹ **256(=16Ã—16)** í† í°, **3Ã—3**ì—ì„œ **121(=11Ã—11)** í† í°. 

---
#### ğŸ“Œ Temporal Scaling & Compression
* **ì‘ë™ ë°©ì‹**: ë¹„ë””ì˜¤ ì…ë ¥ì€ **í”„ë ˆì„ ìˆ˜ F**ë¥¼ ëŠ˜ë ¤(ì˜ˆ: 8â†’32, 256 ë“±) ì‹œê°„ ì •ë³´ë¥¼ ë¨¼ì € í™•ì¥(**Scale**). ê·¸ ë’¤ **ê·¸ë£¹ ë‹¨ìœ„ í‰ê·  í’€ë§(Temporal Averaging)**ìœ¼ë¡œ ì¸ì ‘ í”„ë ˆì„ í† í°ì„ ëª¨ì•„ **ì¤‘ë³µ ì œê±°**(**Compress**).  
* **íš¨ê³¼**: 8â†’32 í”„ë ˆì„ í™•ì¥ ì‹œ Videoâ€‘MME ì •í™•ë„ **+5%p ì´ìƒ** í–¥ìƒ. ë™ì¼ í† í° ìˆ˜ë¡œ ë¹„êµí•˜ë©´ **í™•ì¥ í›„ ì••ì¶•**ì´ **í™•ì¥ ì—†ì´ ë™ì¼ í† í° ìˆ˜**ë³´ë‹¤ ì •í™•ë„ê°€ ë†’ìŒ. 

> **ìˆ˜ì‹/í† í° ìˆ˜ ê°œë…**  
> - (í”„ë ˆì„ ê¸°ì¤€) **í™•ì¥ ì „ ì´ í† í°**: $N_{\text{frame}} \times F$  
> - **gâ€‘í”„ë ˆì„ í‰ê·  í’€ë§ í›„**: $N_{\text{tokens}}' \approx \frac{N_{\text{frame}} \times F}{g}$  
> - í‘œ ì˜ˆì‹œ: 32í”„ë ˆì„ì— **4Ã—** ì••ì¶• â†’ í† í° ìˆ˜ê°€ 8í”„ë ˆì„ baselineê³¼ ë™ì¼(2048)ì´ë©´ì„œ ì •í™•ë„ëŠ” **ìƒíšŒ/ìœ ì§€**. 

---
#### ğŸ“Œ Projector (2â€‘Layer MLP)
* **ì—­í• **: **ì‹œê° ì„ë² ë”© â†’ ì–¸ì–´ ì„ë² ë”© ê³µê°„ ì •ë ¬**. STCë¥¼ ê°•í•˜ê²Œ ì ìš©í•˜ë©´ **í”„ë¡œì í„° í•™ìŠµ ë‚œì´ë„â†‘** â†’ **ì¶”ê°€ VEP ë‹¨ê³„**ë¡œ ë¹„ì „ ì¸ì½”ë”ì™€ í•¨ê»˜ ì¡°ì •í•´ ì •í™•ë„ ì†ì‹¤ì„ ìƒì‡„. 
---

#### ğŸ“Œ Token Processor (LLM, Qwen2 ê³„ì—´)
* **ì—­í• **: í…ìŠ¤íŠ¸/ë¹„ì£¼ì–¼ í† í°ì„ ë°›ì•„ **ì˜¤í† ë¦¬ê·¸ë ˆì‹œë¸Œ**ë¡œ ì‘ë‹µì„ ìƒì„±. NVILAëŠ” **Qwen2**ë¥¼ ë°±ë³¸ìœ¼ë¡œ ë‹¤ì–‘í•œ í¬ê¸°ë¥¼ ì‚¬ìš©.

---

#### ğŸ“Œ (ë§¥ë½) NVILAê°€ ì „ì œí•˜ëŠ” ê¸°ë³¸ ì„¤ì •
* **ë°±ë³¸ ì„ íƒ**: **SigLIP ë¹„ì „ ì¸ì½”ë” + Qwen2 LLM + 2â€‘Layer MLP Projector**.  
* **Baseline í•œê³„**: ê¸°ì¡´ VILAëŠ” ì •ì‚¬ì´ì¦ˆ(ì˜ˆ: 448Ã—448) ê°•ì œ/í”„ë ˆì„ ìˆ˜ ì œí•œ(ì˜ˆ: â‰¤14)ìœ¼ë¡œ **ê³ í•´ìƒë„/ì¥ì‹œê°„ ì…ë ¥ì—ì„œ ì •ë³´ ì†ì‹¤**ì´ ì»¸ìŒ â†’ NVILAëŠ” **Scaleâ€‘thenâ€‘Compress**ë¡œ ì •í™•ë„ ìƒí•œì„ ëŒì–´ì˜¬ë¦° ë’¤, í† í° ìˆ˜ë¥¼ ì¤„ì—¬ **í›ˆë ¨Â·ì¶”ë¡  íš¨ìœ¨**ì„ í™•ë³´.


## âš–ï¸ ê¸°ì¡´ ëª¨ë¸ê³¼ì˜ ë¹„êµ

| í•­ëª©    | ë³¸ ë…¼ë¬¸ (NVILA) | ê¸°ì¡´ ë°©ë²•1 (VILA) | ê¸°ì¡´ ë°©ë²•2 (LLaVA ë“± ì¼ë°˜ VLM) |
| ----- | --------------- | ----------------- | ----------------------------- |
| êµ¬ì¡°    | Scale-then-Compress ì „ëµ (ê³ í•´ìƒë„ â†’ í† í° ì••ì¶•) | ê³ ì • í•´ìƒë„ ì…ë ¥ + ì œí•œëœ í† í° ìˆ˜ | ê³ ì • ì…ë ¥ í¬ê¸°, ë¹„íš¨ìœ¨ì  í† í° ì²˜ë¦¬ |
| í•™ìŠµ ë°©ì‹ | FP8 í›ˆë ¨, Dataset Pruning, ì¶”ê°€ VEP ë‹¨ê³„, End-to-End ìµœì í™” | í‘œì¤€ FP16/FP32, ì œí•œëœ ë°ì´í„° í™œìš© | ì„±ëŠ¥ ìœ„ì£¼ í•™ìŠµ, íš¨ìœ¨í™” ê¸°ë²• ë¯¸ì•½ |
| ëª©ì     | **ì •í™•ë„ì™€ íš¨ìœ¨ì˜ ë™ì‹œ ë‹¬ì„±** (í›ˆë ¨, ë¯¸ì„¸ì¡°ì •, ì¶”ë¡  ì „ ê³¼ì • ìµœì í™”) | ì •í™•ë„ â†‘, ê·¸ëŸ¬ë‚˜ ë©”ëª¨ë¦¬/ì—°ì‚°ëŸ‰ â†‘ | ì •í™•ë„ ìš°ì„ , íš¨ìœ¨ì„± ê³ ë ¤ ë¶€ì¡± |

---

## ğŸ“‰ ì‹¤í—˜ ë° ê²°ê³¼

* **ë°ì´í„°ì…‹**:
  - ì´ë¯¸ì§€: COCO, TextVQA, DocVQA ë“±  
  - ë¹„ë””ì˜¤: Video-MME, EgoSchema ë“±  
* **ë¹„êµ ëª¨ë¸**:
  - VILA (ê¸°ë³¸ ë²„ì „)  
  - ì˜¤í”ˆì†ŒìŠ¤ VLM (LLaVA, Qwen-VL ë“±)  
  - ì¼ë¶€ ìƒìš© ëª¨ë¸ (GPT-4V, Gemini ë“±)  
* **ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ ë° ê²°ê³¼**:

| ëª¨ë¸      | Accuracy | F1 | BLEU | ê¸°íƒ€ (Latency/Cost) |
| ------- | -------- | -- | ---- | ------------------ |
| NVILA    | â†‘ ë™ë“±~ìš°ìˆ˜ | â†‘ | â†‘ | í•™ìŠµ ë¹„ìš© 1.9~5.1Ã— â†“, ì¶”ë¡  ì§€ì—° 1.2~2.8Ã— â†“ |
| ê¸°ì¡´ SOTA | ë†’ìŒ (ì •í™•ë„) | - | - | ë¹„ìš©/ì§€ì—° â†‘ (íš¨ìœ¨ì„± ë¯¸í¡) |

> **ì‹¤í—˜ ê²°ê³¼ ìš”ì•½**  
> - NVILAëŠ” **ê³ í•´ìƒë„ ì´ë¯¸ì§€ + ì¥ì‹œê°„ ë¹„ë””ì˜¤** ì²˜ë¦¬ ì‹œì—ë„ ì •í™•ë„ë¥¼ ìœ ì§€/ìƒìŠ¹.  
> - ë™ì‹œì— **Training ë¹„ìš© 4.5Ã— ì ˆê°**, **Fine-tuning ë©”ëª¨ë¦¬ 3.4Ã— ì ˆê°**, **Pre-filling 1.6~2.2Ã— ê°ì†Œ**, **Decoding 1.2~2.8Ã— ê°ì†Œ**.  
> - ì¦‰, **ì •í™•ë„-íš¨ìœ¨ì„± trade-off ê³¡ì„ ì˜ Pareto Frontier**ë¥¼ í™•ì¥.

---

## âœ… ì¥ì  ë° í•œê³„

### **ì¥ì **:
* â€œScale-then-Compressâ€ë¡œ **ì •í™•ë„ì™€ íš¨ìœ¨ì„±ì˜ ê· í˜•** ë‹¬ì„±.  
* ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ëª¨ë‘ ì ìš© ê°€ëŠ¥í•œ ë²”ìš© êµ¬ì¡°.  
* í•™ìŠµ~ì¶”ë¡  **ìƒì• ì£¼ê¸° ì „ë°˜ íš¨ìœ¨í™”**(FP8, í”„ë£¨ë‹, VEP ë“±).  
* ì˜¤í”ˆ ëª¨ë¸ ì¤‘ **ì‹¤ì œ ì‘ìš©ì— ê°€ì¥ ê°€ê¹Œìš´ íš¨ìœ¨ì„±** í™•ë³´.

### **í•œê³„ ë° ê°œì„  ê°€ëŠ¥ì„±**:
* STCë¥¼ ì§€ë‚˜ì¹˜ê²Œ ì••ì¶•í•˜ë©´ ì—¬ì „íˆ ì •í™•ë„ ì†ì‹¤ ë°œìƒ â†’ ë³´ì™„ í•™ìŠµ(VEP)ì´ í•„ìš”.  
* FP8 í•™ìŠµê³¼ í”„ë£¨ë‹ ê¸°ë²•ì€ í•˜ë“œì›¨ì–´/í”„ë ˆì„ì›Œí¬ ì˜ì¡´ì„±ì´ ìˆìŒ.  
* ì¼ë¶€ ë„ë©”ì¸(ì˜ˆ: ì˜ë£Œ, ë¡œë³´í‹±ìŠ¤)ì—ì„œëŠ” ì•„ì§ fine-tuning í•„ìš”.  
* ì•„ì§ ì—°êµ¬ ì´ˆê¸° ë‹¨ê³„ â†’ ëŒ€ê·œëª¨ ìƒìš© VLM ëŒ€ë¹„ ë²”ìš©ì„± ê²€ì¦ ë¶€ì¡±.

---

## ğŸ§  TL;DR â€“ í•œëˆˆì— ìš”ì•½

> NVILAëŠ” **â€œí™•ëŒ€ í›„ ì••ì¶•(Scale-then-Compress)â€ ì „ëµ**ìœ¼ë¡œ  
> **ì •í™•ë„ì™€ íš¨ìœ¨ì„±ì˜ ìƒˆë¡œìš´ Pareto Frontier**ë¥¼ ì œì‹œí•œ ë¹„ì „-ì–¸ì–´ ëª¨ë¸.  
> í›ˆë ¨, ë¯¸ì„¸ì¡°ì •, ì¶”ë¡  ì „ ê³¼ì •ì—ì„œ **ë¹„ìš© ì ˆê° + ì •í™•ë„ ìœ ì§€/í–¥ìƒ**ì„ ë™ì‹œì— ë‹¬ì„±.

| êµ¬ì„± ìš”ì†Œ  | ì„¤ëª… |
| ------ | -- |
| í•µì‹¬ ëª¨ë“ˆ  | Dynamic-S2 (ë©€í‹°ìŠ¤ì¼€ì¼ íƒ€ì¼ë§), STC (Spatial Token Compression), Temporal Compression |
| í•™ìŠµ ì „ëµ  | FP8 í›ˆë ¨, Dataset Pruning, VEP ë‹¨ê³„ (ì••ì¶• í›„ ì •ë°€ ë³´ì •) |
| ì „ì´ ë°©ì‹  | SigLIP Encoder + Qwen2 ê¸°ë°˜ LLM + 2-layer MLP Projector |
| ì„±ëŠ¥/íš¨ìœ¨ì„± | ì •í™•ë„ ìœ ì§€Â·ìƒìŠ¹, í•™ìŠµ ë¹„ìš© 4.5Ã— ì ˆê°, ì¶”ë¡  ì§€ì—° 2.8Ã— ê°ì†Œ |

---

## ğŸ”— ì°¸ê³  ë§í¬ (References)

* [ğŸ“„ arXiv ë…¼ë¬¸](https://arxiv.org/abs/2412.04468)  
* [ğŸ’» GitHub (ì˜ˆì‹œ placeholder)](https://github.com/NVILA-Team/NVILA)  
* [ğŸ“ˆ Papers with Code](https://paperswithcode.com/paper/nvila-efficient-frontier-visual-language)  



