# ğŸ“˜ VQ-VAE2 (Hierarchical Neural Discrete Representation Learning)

## 1. ê°œìš” (Overview)

* **ì œëª©**: Hierarchical Neural Discrete Representation Learning (VQ-VAE2)  
* **ì €ì**: Aaron van den Oord, Yazhe Li, Igor Babuschkin, Karen Simonyan, Oriol Vinyals, Andrew Brock, Koray Kavukcuoglu  
* **ì†Œì†**: DeepMind, Google Brain  
* **í•™íšŒ**: NeurIPS 2019  
* **ë§í¬**: [arXiv](https://arxiv.org/abs/1906.00446) / [GitHub (DeepMind)](https://github.com/deepmind/vq-vae) / [Papers with Code](https://paperswithcode.com/paper/hierarchical-neural-discrete-representation)

> **ë…¼ë¬¸ ì„ ì • ì´ìœ **:  
> ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±ì—ì„œ discrete latent representationì´ ê°€ì§€ëŠ” ì¥ì ì„ ê³„ì¸µì  êµ¬ì¡°ë¡œ í™•ì¥í•œ VQ-VAE2ì˜ í•µì‹¬ ì•„ì´ë””ì–´ì™€ ì„±ëŠ¥ í–¥ìƒ ê¸°ë²•ì„ ì´í•´í•´, í–¥í›„ generative ëª¨ë¸ ì—°êµ¬ ë° ì‹¤í—˜ì— ì ìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì  ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ê³ ì  
>
> **ê°„ë‹¨í•œ ë„ì…ë¶€**:  
> ì „í†µì ì¸ VAE ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì€ ì—°ì† ì ì¬ ê³µê°„ì˜ í•œê³„ë¡œ ì¸í•´ ì„¸ë°€í•œ ë””í…Œì¼ í‘œí˜„ê³¼ ë‹¤ì–‘ì„± í™•ë³´ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. VQ-VAE2ëŠ” ë²¡í„° ì–‘ìí™”(Vector Quantization) ê¸°ë²•ì„ ì´ìš©í•´ discrete latentë¥¼ ë„ì…í•˜ê³ , ì´ë¥¼ ìƒìœ„(ì €í•´ìƒë„)ì™€ í•˜ìœ„(ê³ í•´ìƒë„) ë‹¨ê³„ë¡œ ê³„ì¸µí™”í•¨ìœ¼ë¡œì¨ ê¸€ë¡œë²Œ êµ¬ì¡°ì™€ ë¡œì»¬ ë””í…Œì¼ì„ ë™ì‹œì— íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµ, BigGAN ìˆ˜ì¤€ì˜ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ë‚´ëŠ” ì„±ê³¼ë¥¼ ë³´ì˜€ë‹¤.

---
## 2. ë¬¸ì œ ì •ì˜ (Problem Formulation)

**ë¬¸ì œ ë° ê¸°ì¡´ í•œê³„**:

* **ì—°ì† ì ì¬ ê³µê°„ì˜ í‘œí˜„ë ¥ í•œê³„**  
  ê¸°ì¡´ VAEë‚˜ GAN ê¸°ë°˜ ëª¨ë¸ì€ ì—°ì†ì ì¸ ì ì¬(z) ê³µê°„ì— ì˜ì¡´í•˜ê¸° ë•Œë¬¸ì—, ë³µì¡í•œ ê¸€ë¡œë²Œ êµ¬ì¡°ì™€ ë¯¸ì„¸í•œ ë¡œì»¬ ë””í…Œì¼ì„ ë™ì‹œì— ê³ í•´ìƒë„ë¡œ ìº¡ì²˜í•˜ê¸° ì–´ë ¤ì›€.  
* **ë‹¨ì¼ ìˆ˜ì¤€ì˜ ì ì¬ í‘œí˜„ìœ¼ë¡œ ì¸í•œ í’ˆì§ˆ ì €í•˜**  
  í•˜ë‚˜ì˜ latent ì½”ë“œë¶ë§Œ ì‚¬ìš©í•˜ëŠ” VQ-VAEëŠ” ì „ì²´ ì´ë¯¸ì§€ êµ¬ì¡°ë‚˜ í…ìŠ¤ì²˜ ë””í…Œì¼ ì¤‘ í•˜ë‚˜ë¥¼ í¬ìƒí•˜ê²Œ ë˜ê³ , ê³ í•´ìƒë„ í•©ì„± ì‹œ ìƒ˜í”Œ í’ˆì§ˆê³¼ ë‹¤ì–‘ì„±ì´ ì œí•œë¨.

**ì œì•ˆ ë°©ì‹**:

* **ê³„ì¸µì  ë””ìŠ¤í¬ë¦¬íŠ¸ ì ì¬ í‘œí˜„**  
  â€“ **ìƒìœ„ ë ˆë²¨(ì €í•´ìƒë„)**: ì´ë¯¸ì§€ì˜ í° í‹€ê³¼ ì „ì—­ êµ¬ì¡°ë¥¼ ì••ì¶•í•˜ëŠ” ì €í•´ìƒë„ ì½”ë“œë¶  
  â€“ **í•˜ìœ„ ë ˆë²¨(ê³ í•´ìƒë„)**: ìƒìœ„ ë ˆë²¨ ì¶œë ¥ì„ ë³´ê°•í•˜ì—¬ ì„¸ë°€í•œ í…ìŠ¤ì²˜ì™€ ë””í…Œì¼ì„ ë³µì›í•˜ëŠ” ê³ í•´ìƒë„ ì½”ë“œë¶  
* **ë‘ ë‹¨ê³„ VQ-VAE í•™ìŠµ**  
  â€“ ìƒìœ„ ì¸ì½”ë”/ë””ì½”ë”ë¡œ global latent í•™ìŠµ â†’ ë””ì½”ë”© í›„ ì—…ìƒ˜í”Œë§  
  â€“ ì—…ìƒ˜í”Œëœ íŠ¹ì§•ì— í•˜ìœ„ ì¸ì½”ë”/ë””ì½”ë”ë¥¼ ì ìš©í•´ local latent í•™ìŠµ  
  â€“ ê°ê°ì˜ ë‹¨ê³„ì—ì„œ **ì½”ë“œë¶ ë²¡í„° ì–‘ìí™”** ë° **commitment loss**ë¥¼ ì‚¬ìš©í•´ ì•ˆì •ì  í›ˆë ¨  

> â€» **í•µì‹¬ ê°œë… ì •ì˜**  
> * **Vector Quantization (VQ)**: ì—°ì† ë²¡í„°ë¥¼ ë¯¸ë¦¬ ì •ì˜ëœ ì´ì‚°(codebook) ë²¡í„° ì¤‘ ìµœì¸ì ‘ ì´ì‚°ê°’ìœ¼ë¡œ ë§¤í•‘í•˜ëŠ” ê¸°ë²•  
> * **Codebook**: ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” ì´ì‚° ì ì¬ ë²¡í„°ì˜ ì§‘í•©, ê° ë²¡í„°ëŠ” ì´ë¯¸ì§€ì˜ íŠ¹ì • íŒ¨í„´ ë˜ëŠ” êµ¬ì¡°ë¥¼ ëŒ€í‘œ  
> * **Commitment Loss**: ì¸ì½”ë” ì¶œë ¥ì´ ì½”ë“œë¶ ë²¡í„°ì— â€œê³¼ë„í•˜ê²Œ ì ë¦¬ì§€â€ ì•Šë„ë¡ ìœ ë„í•´ í‘œí˜„ì˜ ë‹¤ì–‘ì„±ê³¼ ì•ˆì •ì„±ì„ ë†’ì´ëŠ” í˜ë„í‹°  
> * **ê³„ì¸µì  êµ¬ì¡° (Hierarchical Representation)**: ë‹¤ì¤‘ í•´ìƒë„/ë‹¨ê³„ì—ì„œ ì ì¬ë¥¼ ë¶„ë¦¬ í•™ìŠµí•´, ì „ì—­ êµ¬ì¡°ì™€ ë¡œì»¬ ë””í…Œì¼ì„ ê°ê° ìµœì í™”  
---  
## 3. ëª¨ë¸ êµ¬ì¡° (Architecture)

### ì „ì²´ êµ¬ì¡°

![ëª¨ë¸ êµ¬ì¡°](path/to/vq-vae2_architecture.png)

* ì…ë ¥ ì´ë¯¸ì§€ $x \in \mathbb{R}^{H\times W\times 3}$ë¥¼ ìƒìœ„ ì¸ì½”ë” $E^t$ì— íˆ¬ì…í•´ ì €í•´ìƒë„ íŠ¹ì§• ë§µ $f^t = E^t(x)$ì„ ì–»ìŠµë‹ˆë‹¤.  
* ë²¡í„° ì–‘ìí™” ëª¨ë“ˆ $VQ^t$ê°€ $f^t$ë¥¼ ì½”ë“œë¶ $\{e^t_k\}_{k=1}^{K_t}$ì—ì„œ ìµœê·¼ì ‘ ì„ë² ë”©ìœ¼ë¡œ ì–‘ìí™”í•˜ì—¬ ì´ì‚° í‘œí˜„ $z^t$ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  
* ìƒìœ„ ë””ì½”ë” $D^t$ê°€ $z^t$ë¥¼ ì—…ìƒ˜í”Œë§í•˜ì—¬ ì „ì—­ êµ¬ì¡° ì •ë³´ë¥¼ ë‹´ì€ ë³´ê°„ëœ íŠ¹ì§• ë§µ $\tilde f^t$ë¥¼ ë³µì›í•©ë‹ˆë‹¤.  
* í•˜ìœ„ ì¸ì½”ë” $E^b$ëŠ” ì›ë³¸ ì´ë¯¸ì§€ $x$ì™€ $\tilde f^t$ë¥¼ ê²°í•©í•´ ê³ í•´ìƒë„ íŠ¹ì§• ë§µ $f^b = E^b(x,\tilde f^t)$ì„ ì‚°ì¶œí•©ë‹ˆë‹¤.  
* í•˜ìœ„ ë²¡í„° ì–‘ìí™” $VQ^b$ê°€ $f^b$ë¥¼ ì½”ë“œë¶ $\{e^b_k\}_{k=1}^{K_b}$ì—ì„œ ì–‘ìí™”í•´ ì´ì‚° í‘œí˜„ $z^b$ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  
* ìµœì¢… ë””ì½”ë” $D^b$ëŠ” $z^t$ì™€ $z^b$ë¥¼ ê²°í•©í•´ ê³ í•´ìƒë„ ì´ë¯¸ì§€ $\hat{x}$ë¥¼ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.  
* Autoregressive Prior ë„¤íŠ¸ì›Œí¬(ì˜ˆ: Gated PixelCNN)ëŠ” $p(z^t)$ ë° $p(z^b \mid z^t)$ë¥¼ í•™ìŠµí•´, ì‹¤ì œ ìƒ˜í”Œë§ ë‹¨ê³„ì—ì„œ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

---

### ğŸ’  í•µì‹¬ ëª¨ë“ˆ ë˜ëŠ” êµ¬ì„± ìš”ì†Œ

#### ğŸ“Œ Top-Level Vector Quantizer (VQÂ¹)

* **ì…ë ¥**: ì €í•´ìƒë„ íŠ¹ì§• ë§µ $f^t \in \mathbb{R}^{h\times w\times D}$  
* **ì–‘ìí™” ë°©ì‹**:  

```math
k^* = \arg\min_k \|f^t_i - e^t_k\|_2
```

```math
z^t_i = e^t_{k^*}
```

* **Loss êµ¬ì„±**:  

```math
\|\text{sg}[f^t] - e^t_{k^*}\|_2^2
```

```math
\beta \|f^t - \text{sg}[e^t_{k^*}]\|_2^2
```
* **VQ-VAE ëŒ€ë¹„ ì°¨ë³„ì **:  
  - ë‹¨ì¼ ë ˆë²¨ ëŒ€ì‹  ëŒ€ê·œëª¨ ì½”ë“œë¶ $(K_t \gg)$ê³¼ ê¹Šì€ ì„ë² ë”© ì°¨ì› $(D \gg)$ì„ ì‚¬ìš©í•´ ì „ì—­ êµ¬ì¡° í‘œí˜„ë ¥ ê·¹ëŒ€í™”  
  - ê³„ì¸µì  ë¶„ë¦¬ë¡œ local/global ìƒì¶© ë¬¸ì œ í•´ì†Œ  

#### ğŸ“Œ Bottom-Level Vector Quantizer (VQÂ²)

* **ì…ë ¥**: ì—…ìƒ˜í”Œëœ ì „ì—­ íŠ¹ì§• $\tilde{f}^t$ì™€ ì›ë³¸ ì„ë² ë”©ì„ ê²°í•©í•œ $f^b \in \mathbb{R}^{H\times W\times D}$  
* **ì–‘ìí™” ë°©ì‹**: VQÂ¹ì™€ ë™ì¼í•˜ë˜, ì½”ë“œë¶ $\{e^b_k\}$ì„ í†µí•´ local ë””í…Œì¼ í•™ìŠµ  
* **ì°¨ë³„ì **: ì „ì—­(latent)ê³¼ êµ­ë¶€(latent)ë¥¼ ë¶„ë¦¬í•´ ì²˜ë¦¬í•¨ìœ¼ë¡œì¨ ê³ í•´ìƒë„ í…ìŠ¤ì²˜ì™€ ë””í…Œì¼ì„ ë™ì‹œì— ë³´ì¡´  

#### ğŸ“Œ Autoregressive Prior Network (PixelCNN)

* **ì—­í• **:  
  - ì „ì—­ ì ì¬ $z^t$ì— ëŒ€í•œ ì‚¬ì „ë¶„í¬ $p(z^t)$ í•™ìŠµ  
  - ì¡°ê±´ë¶€ ë¶„í¬ $p(z^b \mid z^t)$ í•™ìŠµ  
* **êµ¬í˜„**: Gated PixelCNN êµ¬ì¡°ë¥¼ ì±„íƒí•´ ê° ìœ„ì¹˜ì˜ ì´ì‚° ì½”ë“œ ì¸ë±ìŠ¤ë¥¼ ì´ì „ ì½”ë“œ ìˆœì°¨ì ìœ¼ë¡œ ì˜ˆì¸¡  
* **VQ-VAE ëŒ€ë¹„ ì°¨ë³„ì **:  
  - ë‹¨ì¼ prior ëŒ€ì‹  ê³„ì¸µì  priorë¡œ ë³µì¡ë„ ë¶„ì‚°  
  - ì „ì—­ ì½”ë“œ ìƒì„± í›„ í•˜ìœ„ ì½”ë“œë¥¼ ì¡°ê±´ë¶€ë¡œ ìƒì„±í•´ ìƒ˜í”Œ í’ˆì§ˆ ë° ë‹¤ì–‘ì„± ëŒ€í­ ê°œì„   

---

**ê¸°ì¡´ VQ-VAEì™€ì˜ í•µì‹¬ ì°¨ë³„ì  ìš”ì•½**  
1. **ê³„ì¸µí™”ëœ ì´ì‚° í‘œí˜„**: í•˜ë‚˜ì˜ latent ëŒ€ì‹  ë‘ ë‹¨ê³„(latentÂ¹/global, latentÂ²/local)ë¡œ ë¶„ë¦¬  
2. **í™•ì¥ëœ ì½”ë“œë¶ ìš©ëŸ‰**: ì „ì—­ ë° êµ­ë¶€ ì½”ë“œë¶ í¬ê¸°ì™€ ì„ë² ë”© ì°¨ì› ì¦ê°€  
3. **ê³„ì¸µì  Autoregressive Prior**: $p(z^t)\to p(z^b\mid z^t)$ìœ¼ë¡œ ìˆœì°¨ì  ìƒ˜í”Œë§  
4. **ê³ í•´ìƒë„ ì´ë¯¸ì§€ ì í•©ì„±**: ê¸€ë¡œë²Œ êµ¬ì¡°ì™€ ë¯¸ì„¸ ë””í…Œì¼ì„ ë™ì‹œì— í¬ì°©í•´ BigGAN ìˆ˜ì¤€ ì„±ëŠ¥ ë‹¬ì„±
---

## âš–ï¸ ê¸°ì¡´ ëª¨ë¸ê³¼ì˜ ë¹„êµ

| í•­ëª©       | ë³¸ ë…¼ë¬¸ (VQ-VAE2)                       | ê¸°ì¡´ ë°©ë²•1 (VQ-VAE)                                 | ê¸°ì¡´ ë°©ë²•2 (BigGAN-deep)                         |
| ---------- | --------------------------------------- | --------------------------------------------------- | ----------------------------------------------- |
| **êµ¬ì¡°**   | ë‹¤ë‹¨ê³„ ê³„ì¸µì  VQ (ê¸€ë¡œë²ŒÂ·ë¡œì»¬ codebook)  | ë‹¨ì¼ ìˆ˜ì¤€ VQ codebook                              | Generator-Discriminator êµ¬ì¡° (Adversarial)      |
| **í•™ìŠµ ë°©ì‹** | ë¹„ì§€ë„ ê³„ì¸µì  VQ í•™ìŠµ + Autoregressive Prior  
              | ë¹„ì§€ë„ VQ í•™ìŠµ  
              | ì ëŒ€ì  í•™ìŠµ (GAN)                              |
| **ëª©ì **   | ê³ í•´ìƒë„ ì´ë¯¸ì§€ì˜ ì „ì—­ êµ¬ì¡°ì™€ ì„¸ë¶€ ë””í…Œì¼ ë™ì‹œ í•™ìŠµ  | ê³ í•´ìƒë„ì—ì„œ ìƒ˜í”Œ í’ˆì§ˆÂ·ë‹¤ì–‘ì„± í•œê³„  | ìš°ìˆ˜í•œ FID/IS ì„±ëŠ¥, ê·¸ëŸ¬ë‚˜ ëª¨ë“œ ë¶•ê´´ ë° ë‹¤ì–‘ì„± ì €í•˜ ìœ„í—˜  |

---

## ğŸ“‰ ì‹¤í—˜ ë° ê²°ê³¼

* **ë°ì´í„°ì…‹**:  
  * ImageNet (256Ã—256)  
  * FFHQ (1024Ã—1024)

* **ë¹„êµ ëª¨ë¸**:  
  * VQ-VAE (Neural Discrete Representation Learning) 
  * BigGAN-deep (State-of-the-Art GAN) 

* **ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ ë° ê²°ê³¼**:  
  - **ìƒ˜í”Œ í’ˆì§ˆ**:  
    - VQ-VAE2ëŠ” ImageNet 256Ã—256ì—ì„œ BigGAN-deepì— ê·¼ì ‘í•˜ëŠ” FID ë° Inception Scoreë¥¼ ë‹¬ì„±í•˜ë©°,  
      ëª¨ë“œ ë¶•ê´´ ì—†ì´ ë†’ì€ ë‹¤ì–‘ì„±ì„ ìœ ì§€ 
  - **ìƒ˜í”Œë§ ì†ë„**:  
    - í”½ì…€ ê³µê°„ì—ì„œ ì§ì ‘ ìƒ˜í”Œë§í•˜ëŠ” ê²ƒë³´ë‹¤ **ì•½ 30ë°° ë¹ ë¥¸** Latent ê³µê°„ ìƒ˜í”Œë§ ì†ë„ 

> **ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ ë° í•´ì„**  
> VQ-VAE2ëŠ” ê³„ì¸µì  ì´ì‚° í‘œí˜„ê³¼ ê°•ë ¥í•œ Autoregressive Prior ì¡°í•©ì„ í†µí•´,  
> ê¸°ì¡´ VQ-VAE ëŒ€ë¹„ FIDë¥¼ ëŒ€í­ ê°ì†Œì‹œí‚¤ê³ (â‰ˆ33â†’â‰ˆ11),  
> BigGAN-deep ìˆ˜ì¤€ì˜ ìƒ˜í”Œ í’ˆì§ˆê³¼ ë‹¤ì–‘ì„±ì„ ë™ì‹œì— í™•ë³´í–ˆë‹¤.

---

## âœ… ì¥ì  ë° í•œê³„

### **ì¥ì **  
* **ê³ í•´ìƒë„ ìƒ˜í”Œ í’ˆì§ˆ**: ê¸€ë¡œë²Œ êµ¬ì¡°ì™€ ë¡œì»¬ ë””í…Œì¼ì„ ë™ì‹œì— í¬ì°©, BigGAN ìˆ˜ì¤€ì˜ FID/IS ë‹¬ì„± 
* **ë‹¤ì–‘ì„± ìœ ì§€**: Mode Collapse ì—†ì´ ë°ì´í„° ë¶„í¬ì˜ ë‹¤ì–‘í•œ ëª¨ë“œë¥¼ í¬ê´„ 
* **ë¹ ë¥¸ ìƒ˜í”Œë§**: Latent ê³µê°„ì— êµ­í•œëœ Autoregressive ìƒ˜í”Œë§ìœ¼ë¡œ í”½ì…€ ê³µê°„ë³´ë‹¤ íšê¸°ì  ì†ë„ ê°œì„  
* **ì—”ì½”ë”©/ë””ì½”ë”© íš¨ìœ¨**: ë‹¨ìˆœ Feed-forward Encoder/Decoder êµ¬ì¡°ë¡œ ì‹¤ì‹œê°„ ì‘ìš©ì— ì í•©  

### **í•œê³„ ë° ê°œì„  ê°€ëŠ¥ì„±**  
* **Prior í•™ìŠµ ë¹„ìš©**: ëŒ€ê·œëª¨ Autoregressive Prior í•™ìŠµ ì‹œ ë©”ëª¨ë¦¬Â·ì—°ì‚° ë¶€ë‹´ ì¦ê°€  
* **ìˆœì°¨ì  ìƒ˜í”Œë§**: Latent ê³µê°„ì—ì„œëŠ” ë¹¨ë¼ì¡Œìœ¼ë‚˜ ì—¬ì „íˆ ìˆœì°¨ì  íŠ¹ì„±ìœ¼ë¡œ ì‹¤ì‹œê°„ ì œì•½  
* **ì•„í‚¤í…ì²˜ ë³µì¡ë„**: ë‘ ë‹¨ê³„ VQ ë° Prior ë„¤íŠ¸ì›Œí¬ ì„¤ê³„Â·íŠœë‹ ë‚œì´ë„ ë†’ìŒ  
* **ì¡°ê±´ë¶€ ìƒ˜í”Œë§ í•œê³„**: Classifier-based rejection sampling í•„ìš”ì„±ì´ ì¼ë¶€ í’ˆì§ˆ í–¥ìƒ ê³¼ì •ì— ë„ì…ë¨  

---

## ğŸ§  TL;DR â€“ í•œëˆˆì— ìš”ì•½

> VQ-VAE2ëŠ” **ê³„ì¸µì  ì´ì‚° ì ì¬ í‘œí˜„**ê³¼ **Autoregressive Prior**ë¥¼ ê²°í•©í•´,  
> ê¸€ë¡œë²Œ êµ¬ì¡°ì™€ ë¡œì»¬ ë””í…Œì¼ì„ ë™ì‹œì— í•™ìŠµí•˜ë©°  
> **ê³ í•´ìƒë„ ì´ë¯¸ì§€**ì—ì„œ BigGAN ìˆ˜ì¤€ì˜ **ìƒ˜í”Œ í’ˆì§ˆÂ·ë‹¤ì–‘ì„±**ì„  
> **30Ã— ë¹ ë¥¸** Latent ê³µê°„ ìƒ˜í”Œë§ìœ¼ë¡œ ë‹¬ì„±í•œ ëª¨ë¸ì…ë‹ˆë‹¤.

| êµ¬ì„± ìš”ì†Œ      | ì„¤ëª…                                                           |
| -------------- | -------------------------------------------------------------- |
| **í•µì‹¬ ëª¨ë“ˆ**    | Top-Level VQ + Bottom-Level VQ + Hierarchical PixelCNN Prior  |
| **í•™ìŠµ ì „ëµ**    | Two-Stage VQ í•™ìŠµ â†’ Latent Prior í•™ìŠµ (PixelCNN with Self-Attention) |
| **ì „ì´ ë°©ì‹**    | ë¹„ì§€ë„ ì••ì¶• â†’ Autoregressive Prior ì—°ê³„                         |
| **ì„±ëŠ¥/íš¨ìœ¨ì„±** | BigGAN-like FID/IS + ëª¨ë“œ ë¶•ê´´ ì—†ìŒ + 30Ã— ë¹ ë¥¸ ìƒ˜í”Œë§ ì†ë„       |

---

## ğŸ”— ì°¸ê³  ë§í¬ (References)

* [ğŸ“„ arXiv ë…¼ë¬¸](https://arxiv.org/abs/1906.00446)  
* [ğŸ“„ NeurIPS PDF â€“ Table ë° êµ¬í˜„ ìƒì„¸](https://papers.neurips.cc/paper/9625-generating-diverse-high-fidelity-images-with-vq-vae-2.pdf)  
* [ğŸ’» GitHub (DeepMind VQ-VAE)](https://github.com/deepmind/vq-vae)  
* [ğŸ“ˆ Papers with Code](https://paperswithcode.com/paper/hierarchical-neural-discrete-representation)  



