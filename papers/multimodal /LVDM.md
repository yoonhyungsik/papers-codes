# ğŸ“˜ Latent Video Diffusion Models for High-Fidelity Long Video Generation

## 1. ê°œìš” (Overview)

* **ì œëª©**: Latent Video Diffusion Models for High-Fidelity Long Video Generation
* **ì €ì**: Yingqing He, Tianyu Yang, Yong Zhang, Ying Shan, Qifeng Chen
* **ì†Œì†**: The Hong Kong University of Science and Technology, Tencent AI Lab
* **í•™íšŒ**: arXiv (preprint), 2022.11
* **ë§í¬**: [arXiv](https://arxiv.org/abs/2211.13221) / [GitHub](https://github.com/voletiv/lvdm) / [Papers with Code](https://paperswithcode.com/paper/latent-video-diffusion-models-for-high)

> ê¸°ì¡´ ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸ë“¤ì€ ì˜ìƒ í’ˆì§ˆì´ë‚˜ ì‹œê°„ ê¸¸ì´ ì¸¡ë©´ì—ì„œ ëšœë ·í•œ í•œê³„ë¥¼ ì§€ë…”ê³ , íŠ¹íˆ Diffusion ê¸°ë°˜ ë°©ë²•ì€ í”½ì…€ ê³µê°„ì—ì„œì˜ ìƒ˜í”Œë§ìœ¼ë¡œ ì¸í•´ ê³„ì‚° ë¹„ìš©ì´ ë§¤ìš° ì»¸ë‹¤. ë³¸ ë…¼ë¬¸ì€ ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ VAE ê¸°ë°˜ 3D ë¹„ë””ì˜¤ ì˜¤í† ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ë¥¼ latent spaceë¡œ ì••ì¶•í•˜ê³ , ì´ latent ê³µê°„ì—ì„œì˜ hierarchical diffusion ê³¼ì •ì„ í†µí•´ ê¸´ ê¸¸ì´ì˜ ê³ í•´ìƒë„ ë¹„ë””ì˜¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„í•˜ì˜€ë‹¤. LVDMì€ ì €ì°¨ì› í‘œí˜„ì—ì„œì˜ ìƒì„±ìœ¼ë¡œ ì†ë„ì™€ í’ˆì§ˆ ëª¨ë‘ë¥¼ í™•ë³´í•˜ë©°, text-to-video í™•ì¥ë„ ê°€ëŠ¥í•œ ë²”ìš©ì  êµ¬ì¡°ë¥¼ ì§€ë‹Œë‹¤.


---

## 2. ë¬¸ì œ ì •ì˜ (Problem Formulation)

### **ë¬¸ì œ ë° ê¸°ì¡´ í•œê³„**:

* **ë¹„ë””ì˜¤ ìƒì„±(Video Generation)**ì€ ìì—°ìŠ¤ëŸ½ê³  ì •í•©ì„± ìˆëŠ” ì‹œê³µê°„ì  í‘œí˜„ì´ ìš”êµ¬ë˜ëŠ” ì–´ë ¤ìš´ ìƒì„± ê³¼ì œì„.
* ê¸°ì¡´ ë°©ë²•ë“¤ì€ ë‹¤ìŒê³¼ ê°™ì€ í•œê³„ë¥¼ ê°€ì§:
  - **GAN ê¸°ë°˜ ë¹„ë””ì˜¤ ìƒì„±ê¸°**ëŠ” í›ˆë ¨ ë¶ˆì•ˆì •ì„± ë° í”„ë ˆì„ ì •í•©ì„± ë¶€ì¡±
  - **Autoregressive ëª¨ë¸**ì€ ê³„ì‚° ë¹„ìš©ì´ ë†’ê³  ê¸´ ì‹œí€€ìŠ¤ì—ì„œ ëˆ„ì  ì˜¤ë¥˜ ë°œìƒ
  - **Diffusion ê¸°ë°˜ ë¹„ë””ì˜¤ ìƒì„±ê¸°**ëŠ” í”½ì…€ ê³µê°„ì—ì„œ ì‘ë™ â†’ ê³ í•´ìƒë„ ë¹„ë””ì˜¤ ìƒì„± ì‹œ **ì—°ì‚°ëŸ‰ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ê¸‰ì¦**
* íŠ¹íˆ ê¸´ ì˜ìƒ ìƒì„±(ì˜ˆ: ìˆ˜ë°±~ìˆ˜ì²œ í”„ë ˆì„)ì—ì„œ **ì‹œê° í’ˆì§ˆ ì €í•˜, ì‹œê°„ ì¶• ì •í•©ì„± ë¶•ê´´, í”„ë ˆì„ ë‹¨ì ˆì„± ë¬¸ì œê°€ ë¹ˆë²ˆíˆ ë°œìƒ**

---

### **ì œì•ˆ ë°©ì‹**:

LVDMì€ ì´ëŸ¬í•œ í•œê³„ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì „ëµì„ ì œì•ˆí•¨:

1. **Latent Video Autoencoder**  
   â†’ ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ 3D spatiotemporal latentë¡œ ì••ì¶•í•˜ì—¬ **ì €ì°¨ì›ì—ì„œ diffusion ìˆ˜í–‰**

2. **Hierarchical Latent Diffusion**  
   â†’ ì‹œê°„ í•´ìƒë„ë¥¼ ì ì§„ì ìœ¼ë¡œ í™•ì¥í•˜ë©° í”„ë ˆì„ ìƒì„± â†’ **ìˆ˜ì²œ í”„ë ˆì„ë„ ì•ˆì •ì ìœ¼ë¡œ ìƒì„± ê°€ëŠ¥**

3. **Conditional Latent Perturbation**  
   â†’ ì¡°ê±´ ê¸°ë°˜ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ì—¬ ê¸´ ë¹„ë””ì˜¤ ìƒì„± ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” **drift í˜„ìƒ ì™„í™”**

4. **Unconditional Guidance**  
   â†’ ì¡°ê±´ ì—†ëŠ” ìƒ˜í”Œë§ ê²½ë¡œë¥¼ í•¨ê»˜ ê³ ë ¤í•˜ì—¬ **ìƒ˜í”Œë§ ì•ˆì •ì„± ê°•í™” ë° ë‹¤ì–‘ì„± í™•ë³´**

---

> ### â€» í•µì‹¬ ê°œë… ì •ì˜  
> - **Latent Diffusion**: ë¹„ë””ì˜¤ë¥¼ VAEë¥¼ í†µí•´ latent spaceë¡œ ì••ì¶•í•œ í›„, ê·¸ ê³µê°„ì—ì„œ í™•ì‚°(reverse denoising)ì„ ìˆ˜í–‰í•˜ëŠ” êµ¬ì¡°  
> - **3D Video Autoencoder**: ì‹œê°„ + ê³µê°„ ì¶• ì •ë³´ë¥¼ í†µí•©ì ìœ¼ë¡œ ì¸ì½”ë”©í•˜ëŠ” ì˜¤í† ì¸ì½”ë” êµ¬ì¡°  
> - **Hierarchical Sampling**: coarse temporal step â†’ fine temporal step ìˆœìœ¼ë¡œ í”„ë ˆì„ì„ ì ì§„ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ë°©ì‹  
> - **Latent Perturbation**: condition ì •ë³´ë¥¼ ë” ê°•í•˜ê²Œ ë°˜ì˜í•˜ê¸° ìœ„í•´ latent ê³µê°„ì— ë…¸ì´ì¦ˆë¥¼ ì˜ë„ì ìœ¼ë¡œ ì‚½ì…í•˜ëŠ” ì „ëµ  
> - **Unconditional Guidance**: ì¡°ê±´ ìƒ˜í”Œë§ê³¼ ë¬´ì¡°ê±´ ìƒ˜í”Œë§ ê²°ê³¼ë¥¼ í˜¼í•©í•´ ë” ìœ ì—°í•˜ê³  ì•ˆì •ì ì¸ ìƒì„± ìœ ë„

---

## 3. ëª¨ë¸ êµ¬ì¡° (Architecture)

![ëª¨ë¸êµ¬ì¡°ì¡°]

### ğŸ”· ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì„± íë¦„

LVDMì€ ë¹„ë””ì˜¤ ìƒì„± ê³¼ì •ì„ ë‹¤ìŒì˜ ì„¸ ë‹¨ê³„ë¡œ êµ¬ì„±ëœ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ìˆ˜í–‰í•œë‹¤ë‹¤:
```
[1] ì…ë ¥ ë¹„ë””ì˜¤ ë˜ëŠ” ì¡°ê±´ (ex. í…ìŠ¤íŠ¸ prompt)
                â†“
[2] Video Autoencoder (3D VAE)
                â†“
[3] Latent Representation (T Ã— H' Ã— W' Ã— C)
                â†“
[4] Hierarchical Latent Diffusion
                â†“
[5] Reconstructed Latent
                â†“
[6] VAE Decoder â†’ ìµœì¢… ë¹„ë””ì˜¤ ì¶œë ¥
```

---

### ğŸ’  í•µì‹¬ ëª¨ë“ˆ ë˜ëŠ” êµ¬ì„± ìš”ì†Œ 

---

#### ğŸ”· 1. 3D Video Autoencoder (VAE ê¸°ë°˜)

**ğŸ“Œ ì‘ë™ ë°©ì‹**  
- ì…ë ¥ ë¹„ë””ì˜¤ $x \in \mathbb{R}^{T \times H \times W \times 3}$ëŠ” ì‹œê°„ ì¶• $T$, ê³µê°„ í•´ìƒë„ $H \times W$ë¥¼ ê°–ëŠ” RGB ì‹œí€€ìŠ¤ì…ë‹ˆë‹¤.  
- ì´ ë¹„ë””ì˜¤ëŠ” **3D convolution ê¸°ë°˜ ì¸ì½”ë”**ë¥¼ ê±°ì³ **ì‹œê³µê°„ì ìœ¼ë¡œ ì••ì¶•ëœ latent representation** $z$ë¡œ ë§¤í•‘ë©ë‹ˆë‹¤:

```math
z \in \mathbb{R}^{T \times H' \times W' \times C}
```

- ì´ latentëŠ” ì´í›„ diffusion ê³¼ì •ì—ì„œ ì‚¬ìš©ë˜ë©°, ìµœì¢…ì ìœ¼ë¡œ VAE ë””ì½”ë”ë¥¼ í†µí•´ ì›ë˜ì˜ í•´ìƒë„ë¡œ ë³µì›ë©ë‹ˆë‹¤.

**ğŸ“Œ í•™ìŠµ ëª©í‘œ**  
- reconstruction ì†ì‹¤ + ì •ê·œí™”(KL divergence)ë¥¼ ìµœì†Œí™”í•˜ì—¬ latent ê³µê°„ì´ ìì—°ìŠ¤ëŸ¬ìš´ prior $p(z)$ë¥¼ ë”°ë¥´ë„ë¡ í•™ìŠµí•©ë‹ˆë‹¤.

**ğŸ“Œ ë³µì› ì†ì‹¤ ìˆ˜ì‹**

```math
\mathcal{L}_{\text{VAE}} = \mathbb{E}_{q(z|x)} \left[ \| x - \text{Dec}(z) \|^2 \right] + D_{KL}(q(z|x) \| p(z))
```
**ğŸ“Œ íš¨ê³¼**  
- í”½ì…€ ê³µê°„ë³´ë‹¤ í›¨ì”¬ ì €ì°¨ì›ì¸ latent ê³µê°„ì—ì„œ diffusionì„ ìˆ˜í–‰ â†’ ë©”ëª¨ë¦¬, ì—°ì‚°ëŸ‰ ì ˆê°  
- 3D êµ¬ì¡°ë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ **ì‹œê°„ ì¶• ì—°ì†ì„±(motion consistency)**ì„ ìœ ì§€í•œ ì••ì¶• ê°€ëŠ¥

---

#### ğŸ”· 2. Hierarchical Latent Diffusion

**ğŸ“Œ ì‘ë™ ë°©ì‹**  
- ì „ì²´ ë¹„ë””ì˜¤ë¥¼ í•œ ë²ˆì— ìƒì„±í•˜ì§€ ì•Šê³ , **ì‹œê°„ í•´ìƒë„ë¥¼ ì ì°¨ ì¦ê°€ì‹œí‚¤ëŠ” hierarchical sampling**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

  1. **Coarse step**: ë‚®ì€ frame rate (ì˜ˆ: 8fps) ìˆ˜ì¤€ì˜ latent ì‹œí€€ìŠ¤ë¥¼ ìƒì„±  
  2. **Interpolation**: latent spaceì—ì„œ ì‹œê°„ ì¶• ë³´ê°„ ìˆ˜í–‰  
  3. **Refinement**: ë³´ê°„ëœ latentë¥¼ ê³ í•´ìƒë„ (ì˜ˆ: 30fps ë“±) latentë¡œ ì ì§„ì  refinement

**ğŸ“Œ Denoising Step ìˆ˜ì‹**

```math
z_{t-1} = z_t - \epsilon_{\theta}(z_t, t, c)
```

- $z_t$: í˜„ì¬ timestepì—ì„œì˜ noisy latent

- $\epsilon_{\theta}$: ì¡°ê±´ë¶€ ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ë„¤íŠ¸ì›Œí¬ (U-Net ê³„ì—´)

- $c$: ì¡°ê±´ ì •ë³´ (í…ìŠ¤íŠ¸, í´ë˜ìŠ¤ ë“±)

**ğŸ“Œ íš¨ê³¼**

- ì§§ì€ ì‹œí€€ìŠ¤ì— ë¹„í•´ ê¸´ ë¹„ë””ì˜¤ ìƒì„±ì—ì„œë„ ì‹œê°„ ì¶• ì •í•©ì„± ìœ ì§€

- ê¸´ ì‹œí€€ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìƒì„±í•  ìˆ˜ ìˆìœ¼ë©°, ì ì§„ì  refinementë¡œ ê³ í’ˆì§ˆ ìœ ì§€
---

#### ğŸ”· 3. Conditional Latent Perturbation

**ğŸ“Œ ë¬¸ì œ ì¸ì‹**  
- ì¡°ê±´(condition) ê¸°ë°˜ ë¹„ë””ì˜¤ ìƒì„±ì—ì„œ, ìƒ˜í”Œë§ì´ ê¸¸ì–´ì§ˆìˆ˜ë¡ **ì¡°ê±´ ì •ë³´ê°€ íë ¤ì§€ê³ ** ë‚´ìš©ì´ **drift**ë˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.

**ğŸ“Œ í•´ê²°ì±…**  
- ì¡°ê±´ ì •ë³´ $c$ (ì˜ˆ: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸)ë¡œë¶€í„° perturbation ë²¡í„°ë¥¼ ìƒì„±í•´ **latent ê³µê°„ì— ì§ì ‘ ì£¼ì…**í•©ë‹ˆë‹¤.  
- ì´ë¥¼ í†µí•´ diffusion ë„ì¤‘ì—ë„ ì¡°ê±´ì˜ ì˜í–¥ì„ ì§€ì†ì ìœ¼ë¡œ ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ğŸ“Œ ìˆ˜ì‹**

```math
z_t = z_t + \alpha \cdot \text{Perturb}(c)
```

- $z_t$: í˜„ì¬ timestepì˜ latent

- $\alpha$: ì¡°ê±´ ë…¸ì´ì¦ˆì˜ ë°˜ì˜ ê°•ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°

- $\text{Perturb}(c)$: ì¡°ê±´ ë²¡í„°ì— ëœë¤ ë…¸ì´ì¦ˆë¥¼ ì„ì€ perturbation ì„ë² ë”©

**ğŸ“Œ íš¨ê³¼**

- ì¡°ê±´ ì¼ê´€ì„± ìœ ì§€ (ex. í”„ë¡¬í”„íŠ¸ ì£¼ì œì— ë²—ì–´ë‚˜ì§€ ì•ŠìŒ)

- ê¸´ ì˜ìƒ ìƒì„±ì—ì„œë„ driftë¥¼ ë°©ì§€í•˜ê³  ë‚´ìš© ì•ˆì •ì„± í™•ë³´
---

**ğŸ”· 4. Unconditional Guidance**

**ğŸ“Œ ë¬¸ì œ ì¸ì‹**

- ì¡°ê±´ì´ ëª¨í˜¸í•˜ê±°ë‚˜ ë¶ˆì™„ì „í•œ ê²½ìš°, ëª¨ë¸ì´ mode collapse ë˜ê±°ë‚˜ í’ˆì§ˆì´ ë‚®ì€ ìƒ˜í”Œì„ ìƒì„±í•  ìˆ˜ ìˆìŒ

**ğŸ“Œ í•´ê²° ì „ëµ**

- Classifier-Free Guidance (CFG) ë°©ì‹ì„ ì°¨ìš©í•´

- ì¡°ê±´ì´ ìˆëŠ” ê²½ë¡œì™€ ì¡°ê±´ì´ ì—†ëŠ” ê²½ë¡œì˜ ì˜ˆì¸¡ê°’ì„ í˜¼í•©í•˜ì—¬ ìƒ˜í”Œë§ì„ ìœ ë„í•©ë‹ˆë‹¤.

**ğŸ“Œ ìˆ˜ì‹**
```math
\epsilon_{\text{final}} = (1 + w) \cdot \epsilon_{\theta}(z_t, c) - w \cdot \epsilon_{\theta}(z_t)
```
- $w$: guidance scale â€” ì¡°ê±´ ë°˜ì˜ ê°•ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” ê³„ìˆ˜ (ì¼ë°˜ì ìœ¼ë¡œ 3~7 ì‚¬ì´)

- $\epsilon_{\theta}(z_t, c)$: ì¡°ê±´ì´ í¬í•¨ëœ ë…¸ì´ì¦ˆ ì˜ˆì¸¡

- $\epsilon_{\theta}(z_t)$: ì¡°ê±´ì´ ì—†ëŠ” ë…¸ì´ì¦ˆ ì˜ˆì¸¡

**ğŸ“Œ í•´ì„**

- $w = 0$ì¼ ê²½ìš° â†’ ì™„ì „íˆ unconditional (ì¡°ê±´ ì—†ëŠ” ìƒì„±)

- $w$ê°€ ì»¤ì§ˆìˆ˜ë¡ â†’ ì¡°ê±´ $c$ì— ë” ì •í™•íˆ ë§ëŠ” ìƒ˜í”Œ ìƒì„±

- ë‹¨, ë„ˆë¬´ ë†’ì„ ê²½ìš° ë‹¤ì–‘ì„± ì €í•˜ ê°€ëŠ¥
â†’ ì¡°ê±´ ì •í™•ë„ vs ìƒì„± ë‹¤ì–‘ì„± ê°„ trade-offë¥¼ ì¡°ì ˆí•  ìˆ˜ ìˆìŒ

**ğŸ“Œ íš¨ê³¼**

- í…ìŠ¤íŠ¸ ì¡°ê±´ì´ ëª¨í˜¸í•˜ê±°ë‚˜ ë¶ˆì™„ì „í•œ ê²½ìš°ì—ë„ ì•ˆì •ì ì¸ ê²°ê³¼ ìƒì„± ê°€ëŠ¥

- ë‹¤ì–‘ì„± ìˆëŠ” ìƒ˜í”Œ ìƒì„± ë° mode collapse ë°©ì§€
---
## âš–ï¸ ê¸°ì¡´ ëª¨ë¸ê³¼ì˜ ë¹„êµ

| í•­ëª©       | ë³¸ ë…¼ë¬¸ (LVDM)                         | ê¸°ì¡´ ë°©ë²•1 (VideoGAN)               | ê¸°ì¡´ ë°©ë²•2 (Video Diffusion in Pixel Space)   |
|------------|----------------------------------------|--------------------------------------|------------------------------------------------|
| êµ¬ì¡°       | 3D VAE + Hierarchical Latent Diffusion | CNN ê¸°ë°˜ GAN                         | U-Net ê¸°ë°˜ í™•ì‚° (í”½ì…€ ê³µê°„)                    |
| í•™ìŠµ ë°©ì‹  | VAE ì‚¬ì „í•™ìŠµ í›„, latent diffusion joint í•™ìŠµ | Adversarial Loss ê¸°ë°˜ End-to-End     | í”½ì…€ ê³µê°„ì˜ DDPM í•™ìŠµ, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í¼       |
| ëª©ì        | ê³ í•´ìƒë„ + ì¥ì‹œê°„ ë¹„ë””ì˜¤ ìƒì„±         | ì§§ê³  ë°˜ë³µ ê°€ëŠ¥í•œ low-res ë¹„ë””ì˜¤ ìƒì„± | ê³ í•´ìƒë„ ìƒì„± ê°€ëŠ¥í•˜ë‚˜ ì—°ì‚°ëŸ‰ ë§ê³  ê¸´ ë¹„ë””ì˜¤ ì–´ë ¤ì›€ |
| ì¥ì        | ê³ ì†, ì •í•©ì„±, ê¸¸ì´ í™•ì¥ì„± ëª¨ë‘ í™•ë³´    | ì†ë„ ë¹ ë¦„, êµ¬ì¡° ê°„ë‹¨                 | ê³ í’ˆì§ˆ ìƒ˜í”Œ ìƒì„± ê°€ëŠ¥, CLIP ë“±ê³¼ ê²°í•© ê°€ëŠ¥     |
| í•œê³„       | í…ìŠ¤íŠ¸ ê¸°ë°˜ í™•ì¥ì€ ì•„ì§ ì‹¤í—˜ì          | í’ˆì§ˆ/ì •í•©ì„± ë–¨ì–´ì§                   | ê³„ì‚°ëŸ‰/ì‹œê°„ ë¶€ë‹´ í¬ê³  ì‹œê³µê°„ consistency ë‚®ìŒ |

---

## ğŸ“‰ ì‹¤í—˜ ë° ê²°ê³¼

**ğŸ“Œ ì‚¬ìš© ë°ì´í„°ì…‹**  
- **UCF-101**: ë™ì‘ ì¤‘ì‹¬ ì§§ì€ ë¹„ë””ì˜¤ í´ë¦½  
- **SkyTimelapse**: ì •ì ì¸ ë°°ê²½ + ëŠë¦° ì›€ì§ì„  
- **MEAD**, **FaceForensics**: ì–¼êµ´ ê¸°ë°˜ long-form ë¹„ë””ì˜¤

**ğŸ“Œ ë¹„êµ ëª¨ë¸**  
- VideoGPT  
- Video Diffusion Models (VDM)  
- TATS  
- StyleGAN-V

**ğŸ“Œ ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ**

| ëª¨ë¸           | FVDâ†“     | FIDâ†“     | CLIPSIMâ†‘ | ë¹„ê³                             |
|----------------|----------|----------|----------|---------------------------------|
| **LVDM (ours)** | **256.1** | **45.3** | **0.301** | ì „ì²´ì ìœ¼ë¡œ ê°€ì¥ ìš°ìˆ˜í•œ ì •í•©ì„±    |
| VDM            | 423.5    | 58.1     | 0.211    | í”½ì…€ ê³µê°„ diffusion              |
| TATS           | 287.3    | 51.4     | 0.229    | AR ê¸°ë°˜, ê¸´ ë¹„ë””ì˜¤ ì•½í•¨         |
| StyleGAN-V     | 601.2    | 73.5     | 0.188    | ì–¼êµ´ ë°ì´í„°ëŠ” ê°€ëŠ¥, ì¼ë°˜ì„± ë‚®ìŒ |

> **í•´ì„**: LVDMì€ FVD, FID, CLIPSIM ëª¨ë“  ì§€í‘œì—ì„œ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ê¸°ë¡í•˜ë©°  
> ê³ í•´ìƒë„ ì¥ì‹œê°„ ë¹„ë””ì˜¤ ìƒì„±ì—ì„œ **ì •í•©ì„±ê³¼ í’ˆì§ˆì„ ëª¨ë‘ í™•ë³´í•œ ì²« latent diffusion ê¸°ë°˜ ë°©ë²•**ì„ì„ ì…ì¦í•¨.

---

## âœ… ì¥ì  ë° í•œê³„

### âœ… ì¥ì 

* **Latent space diffusion**ì„ í†µí•œ **ì—°ì‚° íš¨ìœ¨ì„±** í™•ë³´ (ë©”ëª¨ë¦¬/ì†ë„ ëª¨ë‘ ìœ ë¦¬)
* **3D Video Autoencoder**ë¡œ ì‹œê°„-ê³µê°„ ì •ë³´ ë™ì‹œ ì••ì¶• â†’ **motion consistency í–¥ìƒ**
* **Hierarchical time sampling**ì„ í†µí•´ **ìˆ˜ì²œ í”„ë ˆì„ ë¹„ë””ì˜¤ë„ ì•ˆì •ì  ìƒì„±**
* **Perturbation + CFG** ì¡°í•©ìœ¼ë¡œ **ì¡°ê±´ ì •í•©ì„±ê³¼ ë‹¤ì–‘ì„±** ë™ì‹œ í™•ë³´
* ì—¬ëŸ¬ real-world ë°ì´í„°ì…‹ì—ì„œ SOTA ì„±ëŠ¥ ë‹¬ì„±

---

### âš ï¸ í•œê³„ ë° ê°œì„  ê°€ëŠ¥ì„±

* í…ìŠ¤íŠ¸ ê¸°ë°˜ conditional generationì€ ì•„ì§ ì´ˆê¸° ìˆ˜ì¤€ (Prompt-to-video fully end-to-endëŠ” ì•„ë‹˜)
* Autoencoder ì„±ëŠ¥ì— ë”°ë¼ latent í’ˆì§ˆì´ ì œí•œë  ìˆ˜ ìˆìŒ
* ì‹œê° ì •ë³´ ì™¸ì˜ ì˜¤ë””ì˜¤, ìì—°ì–´, multimodal integrationì€ ë¯¸ì§€ì›
* Latent interpolationì´ ê³ ì† ë³€í™” ì¥ë©´ì—ì„œ artifacts ë°œìƒ ê°€ëŠ¥

---

## ğŸ§  TL;DR â€“ í•œëˆˆì— ìš”ì•½

> **LVDM**ì€ 3D VAEë¡œ ë¹„ë””ì˜¤ë¥¼ ì••ì¶•í•œ latent ê³µê°„ì—ì„œ hierarchical diffusionì„ ìˆ˜í–‰í•˜ì—¬,  
> ê³ í•´ìƒë„ì´ë©´ì„œë„ ì‹œê°„ì ìœ¼ë¡œ ê¸´ ë¹„ë””ì˜¤ë¥¼ ë¹ ë¥´ê³  ì•ˆì •ì ìœ¼ë¡œ ìƒì„±í•  ìˆ˜ ìˆëŠ” **ìµœì´ˆì˜ ì‹œê³µê°„ latent ê¸°ë°˜ ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸**ì´ë‹¤.

| êµ¬ì„± ìš”ì†Œ         | ì„¤ëª…                                                       |
|------------------|------------------------------------------------------------|
| í•µì‹¬ ëª¨ë“ˆ         | 3D Video Autoencoder + Hierarchical Latent Diffusion      |
| í•™ìŠµ ì „ëµ         | ì‚¬ì „í•™ìŠµëœ VAE + joint diffusion í•™ìŠµ                     |
| ì „ì´ ë°©ì‹         | coarse-to-fine ì‹œê°„ í•´ìƒë„, condition perturbation ì ìš©   |
| ì„±ëŠ¥/íš¨ìœ¨ì„±       | FVD/FID/CLIPSIMì—ì„œ SOTA ë‹¬ì„±, ê³ í•´ìƒë„+ì¥ì‹œê°„ ì˜ìƒ ê°€ëŠ¥  |

---

## ğŸ”— ì°¸ê³  ë§í¬ (References)

* [ğŸ“„ arXiv ë…¼ë¬¸](https://arxiv.org/abs/2211.13221)
* [ğŸ’» GitHub](https://github.com/voletiv/lvdm)
* [ğŸ“ˆ Papers with Code](https://paperswithcode.com/paper/latent-video-diffusion-models-for-high)




